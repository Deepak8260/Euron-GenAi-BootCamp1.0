{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376e8e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.1.1-cp39-abi3-win_amd64.whl (19.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from chromadb) (4.15.0)\n",
      "Collecting orjson>=3.9.12\n",
      "  Downloading orjson-3.11.3-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Collecting jsonschema>=4.19.0\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Collecting pybase64>=1.4.1\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting tenacity>=8.2.3\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Collecting overrides>=7.3.1\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (6.0.3)\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (1.75.1)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (2.11.10)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (2.2.6)\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting mmh3>=4.0.1\n",
      "  Downloading mmh3-5.2.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.23.1-cp310-cp310-win_amd64.whl (13.5 MB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting tomli>=1.1.0\n",
      "  Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting importlib-metadata>=4.6\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.27.1-cp310-cp310-win_amd64.whl (228 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
      "Collecting durationpy>=0.7\n",
      "  Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Collecting urllib3<2.4.0,>=1.24.2\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.32.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting googleapis-common-protos~=1.57\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.37.0\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Collecting distro>=1.5.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.3)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.9.0)\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Collecting httptools>=0.6.3\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (PEP 517): started\n",
      "  Building wheel for pypika (PEP 517): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=db43cbf073dd07889ea6520348303c62880e266a913aa6ca279b362f881bd29a\n",
      "  Stored in directory: c:\\users\\kumar\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: zipp, importlib-metadata, urllib3, rpds-py, pyreadline3, pyasn1, opentelemetry-api, mdurl, attrs, rsa, referencing, pyasn1-modules, opentelemetry-semantic-conventions, opentelemetry-proto, oauthlib, markdown-it-py, humanfriendly, click, cachetools, websockets, websocket-client, watchfiles, uvicorn, tomli, shellingham, rich, requests-oauthlib, python-dotenv, pyproject-hooks, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-common, jsonschema-specifications, httptools, googleapis-common-protos, google-auth, flatbuffers, durationpy, distro, coloredlogs, backoff, typer, tenacity, pypika, pybase64, posthog, overrides, orjson, opentelemetry-exporter-otlp-proto-grpc, onnxruntime, mmh3, kubernetes, jsonschema, importlib-resources, build, bcrypt, chromadb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "Successfully installed attrs-25.4.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-6.2.0 chromadb-1.1.1 click-8.3.0 coloredlogs-15.0.1 distro-1.9.0 durationpy-0.10 flatbuffers-25.9.23 google-auth-2.41.1 googleapis-common-protos-1.70.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kubernetes-34.1.0 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 orjson-3.11.3 overrides-7.7.0 posthog-5.4.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pypika-0.48.9 pyproject-hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.1 referencing-0.36.2 requests-oauthlib-2.0.0 rich-14.2.0 rpds-py-0.27.1 rsa-4.9.1 shellingham-1.5.4 tenacity-9.1.2 tomli-2.3.0 typer-0.19.2 urllib3-2.3.0 uvicorn-0.37.0 watchfiles-1.1.0 websocket-client-1.9.0 websockets-15.0.1 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b830a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: chromadb\n",
      "Version: 1.1.1\n",
      "Summary: Chroma.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
      "License: \n",
      "Location: c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: tokenizers, opentelemetry-exporter-otlp-proto-grpc, typer, tqdm, onnxruntime, numpy, pydantic, uvicorn, build, pyyaml, overrides, bcrypt, jsonschema, opentelemetry-api, tenacity, typing-extensions, orjson, mmh3, httpx, posthog, grpcio, pybase64, opentelemetry-sdk, pypika, kubernetes, importlib-resources, rich\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17ca70",
   "metadata": {},
   "source": [
    "# üß† **Local ChromaDB Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8707096",
   "metadata": {},
   "source": [
    "This guide explains how to create a **local vector database using ChromaDB**, generate **embeddings from text using an external API**, and perform **semantic search** ‚Äî all stored **locally on your computer**, not on the cloud.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò **What You‚Äôll Learn**\n",
    "\n",
    "By the end of this, you‚Äôll know:\n",
    "\n",
    "1. What embeddings are and why they‚Äôre used.\n",
    "2. How to generate embeddings using an external API.\n",
    "3. How to store and search data locally using **ChromaDB**.\n",
    "4. How to run semantic queries to find similar text.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è **Step 1: Install Required Libraries**\n",
    "\n",
    "You need three Python packages:\n",
    "\n",
    "* `chromadb` ‚Üí Local vector database\n",
    "* `requests` ‚Üí To send API requests\n",
    "* `numpy` ‚Üí To handle numerical vectors\n",
    "\n",
    "Install them using this command:\n",
    "\n",
    "```bash\n",
    "pip install chromadb requests numpy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß© **Step 2: Import the Libraries**\n",
    "\n",
    "```python\n",
    "import requests      # For sending requests to the embedding API\n",
    "import numpy as np   # For numerical array operations\n",
    "import chromadb      # For creating and managing local vector database\n",
    "from chromadb.config import Settings  # For configuring local storage\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* `requests` helps us send text data to an API and receive embeddings (numbers).\n",
    "* `numpy` stores those numbers in a numerical format that‚Äôs easy to process.\n",
    "* `chromadb` is used to create, store, and search through these embeddings.\n",
    "* `Settings` lets us specify where ChromaDB should save the data on your system.\n",
    "\n",
    "---\n",
    "\n",
    "## üß± **Step 3: Initialize a Local ChromaDB Client**\n",
    "\n",
    "```python\n",
    "client = chromadb.Client(\n",
    "    Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        persist_directory=\"./chroma_data\"\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* This line **starts a local ChromaDB database** on your computer.\n",
    "* `chroma_db_impl=\"duckdb+parquet\"` tells ChromaDB to use **DuckDB** (a lightweight local database) with **Parquet** file storage.\n",
    "* `persist_directory=\"./chroma_data\"` means all data will be saved in a folder called `chroma_data` on your machine.\n",
    "\n",
    "üëâ So even if you close your program or restart your system, your stored data won‚Äôt be lost.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÑ **Step 4: Create Your Text Dataset**\n",
    "\n",
    "```python\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"From an early age, he was deeply curious about how machines work and how technology shapes the world.\",\n",
    "    \"Despite challenges, Deepak‚Äôs determination to learn and grow never faded.\",\n",
    "    \"He earned his Bachelor‚Äôs degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.\",\n",
    "    \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "    \"Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.\",\n",
    "    \"Deepak created multiple real-world projects ‚Äî from a Netflix clone to data analysis dashboards ‚Äî showcasing both creativity and logic.\",\n",
    "    \"He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.\",\n",
    "    \"Deepak‚Äôs story reflects passion, perseverance, and the belief that continuous learning can transform one‚Äôs life.\"\n",
    "]\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "This is your **dataset** ‚Äî a list of sentences (called *documents* in ChromaDB).\n",
    "Each sentence will be converted into a **numerical embedding**, stored in the database, and later used for **similarity searches**.\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ **Step 5: Generate Embeddings Using an External API**\n",
    "\n",
    "```python\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"  # API endpoint\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-47df70dff217e205cf4b860bbb11ff1556a1ab993f374b1de33cd037823e0abf\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-small\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)  # Send POST request\n",
    "    data = response.json()  # Convert API response to Python dictionary\n",
    "    \n",
    "    embedding = np.array(data['data'][0]['embedding'])  # Extract the actual numbers\n",
    "    return embedding\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "1. We define a function `generate_embeddings(text)` that takes a sentence as input.\n",
    "2. The API (Euron‚Äôs Embedding API) converts your text into an **embedding vector** (a list of floating-point numbers).\n",
    "3. `requests.post()` sends the text to the API, and `response.json()` gets the reply.\n",
    "4. `embedding` stores the numeric vector returned by the API as a **NumPy array** for easy handling.\n",
    "\n",
    "üëâ **Why embeddings?**\n",
    "Embeddings turn words into numbers that capture meaning.\n",
    "For example:\n",
    "\n",
    "* ‚ÄúPython developer‚Äù and ‚ÄúSoftware engineer‚Äù will have similar embeddings.\n",
    "* ‚ÄúBanana‚Äù and ‚ÄúCar‚Äù will have very different embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ **Step 6: Generate Embeddings for All Sentences**\n",
    "\n",
    "```python\n",
    "embeddings = [generate_embeddings(t) for t in texts]\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "This line **loops through every sentence** in the `texts` list and calls the `generate_embeddings()` function for each one.\n",
    "The result is a list of numerical vectors ‚Äî one for each text.\n",
    "\n",
    "Now you have:\n",
    "\n",
    "* `texts` ‚Üí the original text data\n",
    "* `embeddings` ‚Üí the numerical version of each text\n",
    "\n",
    "---\n",
    "\n",
    "## üß± **Step 7: Create a Collection in ChromaDB**\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* A **collection** is like a folder or table inside ChromaDB.\n",
    "* You can store multiple documents and embeddings inside it.\n",
    "* Here, the collection is named `\"kumar_collection\"`.\n",
    "\n",
    "üëâ You can later create other collections like `\"resume_data\"`, `\"project_notes\"`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© **Step 8: Add Your Data to the Collection**\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=texts,                        # Original text data\n",
    "    embeddings=embeddings,                  # Numeric embeddings\n",
    "    ids=[str(i) for i in range(len(texts))] # Unique IDs for each text\n",
    ")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "This stores everything inside ChromaDB.\n",
    "\n",
    "* `documents`: the actual sentences.\n",
    "* `embeddings`: the numerical representations.\n",
    "* `ids`: unique identifiers (`\"0\"`, `\"1\"`, `\"2\"`, ‚Ä¶) for each text.\n",
    "\n",
    "Now ChromaDB knows which embedding belongs to which document.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Step 9: Check What‚Äôs Stored**\n",
    "\n",
    "```python\n",
    "print(collection.count())   # Shows total number of stored items\n",
    "print(collection.get())     # Retrieves stored data (texts, embeddings, IDs)\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* `count()` tells you how many documents exist in your collection.\n",
    "* `get()` returns everything that‚Äôs stored ‚Äî including your documents and IDs.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç **Step 10: Query Your Database (Semantic Search)**\n",
    "\n",
    "Now let‚Äôs find which stored sentences are **most similar** to a new input query.\n",
    "\n",
    "```python\n",
    "query = \"hands-on experience with Python\"\n",
    "embed_query = generate_embeddings(query)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[embed_query],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "1. You create a new query text (`\"hands-on experience with Python\"`).\n",
    "2. Convert it into an embedding using the same API (`generate_embeddings(query)`).\n",
    "3. `collection.query()` searches inside your database for **the most similar stored embeddings**.\n",
    "4. `n_results=2` means you want the top 2 most similar sentences.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ **Sample Output**\n",
    "\n",
    "```python\n",
    "{\n",
    "  'ids': [['5', '4']],\n",
    "  'documents': [[\n",
    "      \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "      \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\"\n",
    "  ]],\n",
    "  'distances': [[0.7931717038154602, 1.0989384651184082]]\n",
    "}\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* `'ids'`: IDs of the most similar documents found.\n",
    "* `'documents'`: The actual text results.\n",
    "* `'distances'`: How close each result is to your query.\n",
    "\n",
    "  * Smaller distance = higher similarity.\n",
    "\n",
    "So the result shows that:\n",
    "\n",
    "> The query ‚Äúhands-on experience with Python‚Äù is most similar to the sentence about Deepak‚Äôs hands-on Python experience (ID 5).\n",
    "\n",
    "---\n",
    "\n",
    "## üíæ **Step 11: Saving and Reloading Data**\n",
    "\n",
    "Your data is already saved locally (because we used `persist_directory=\"./chroma_data\"`).\n",
    "If you restart your Python program, you can reload the same collection like this:\n",
    "\n",
    "```python\n",
    "from chromadb.config import Settings\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client(\n",
    "    Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        persist_directory=\"./chroma_data\"\n",
    "    )\n",
    ")\n",
    "\n",
    "collection = client.get_collection(\"kumar_collection\")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* This reopens the database stored in `./chroma_data`.\n",
    "* You can now continue querying or adding new data without losing anything.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Step 12: Full Working Code (Everything Together)**\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# 1Ô∏è‚É£ Initialize ChromaDB (local persistent mode)\n",
    "client = chromadb.Client(\n",
    "    Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=\"./chroma_data\")\n",
    ")\n",
    "\n",
    "# 2Ô∏è‚É£ Prepare the text dataset\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"From an early age, he was deeply curious about how machines work and how technology shapes the world.\",\n",
    "    \"Despite challenges, Deepak‚Äôs determination to learn and grow never faded.\",\n",
    "    \"He earned his Bachelor‚Äôs degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.\",\n",
    "    \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "    \"Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.\",\n",
    "    \"Deepak created multiple real-world projects ‚Äî from a Netflix clone to data analysis dashboards ‚Äî showcasing both creativity and logic.\",\n",
    "    \"He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.\",\n",
    "    \"Deepak‚Äôs story reflects passion, perseverance, and the belief that continuous learning can transform one‚Äôs life.\"\n",
    "]\n",
    "\n",
    "# 3Ô∏è‚É£ Function to generate embeddings\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-47df70dff217e205cf4b860bbb11ff1556a1ab993f374b1de33cd037823e0abf\"\n",
    "    }\n",
    "    payload = {\"input\": text, \"model\": \"text-embedding-3-small\"}\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    return embedding\n",
    "\n",
    "# 4Ô∏è‚É£ Generate embeddings for all texts\n",
    "embeddings = [generate_embeddings(t) for t in texts]\n",
    "\n",
    "# 5Ô∏è‚É£ Create a collection and add data\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "collection.add(documents=texts, embeddings=embeddings, ids=[str(i) for i in range(len(texts))])\n",
    "\n",
    "# 6Ô∏è‚É£ Query for similar text\n",
    "query = \"hands-on experience with Python\"\n",
    "embed_query = generate_embeddings(query)\n",
    "results = collection.query(query_embeddings=[embed_query], n_results=2)\n",
    "\n",
    "# 7Ô∏è‚É£ Show results\n",
    "print(results)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Final Summary**\n",
    "\n",
    "| Step | What It Does        | Explanation                                   |\n",
    "| ---- | ------------------- | --------------------------------------------- |\n",
    "| 1    | Initialize ChromaDB | Creates a local database folder to store data |\n",
    "| 2    | Prepare texts       | List of sentences you want to store           |\n",
    "| 3    | Generate embeddings | Converts text ‚Üí numeric vectors               |\n",
    "| 4    | Add to collection   | Stores texts + embeddings in ChromaDB         |\n",
    "| 5    | Query               | Searches for the most similar texts           |\n",
    "| 6    | Reload              | Allows reuse of the same local database later |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9aaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"From an early age, he was deeply curious about how machines work and how technology shapes the world.\",\n",
    "    \"Despite challenges, Deepak‚Äôs determination to learn and grow never faded.\",\n",
    "    \"He earned his Bachelor‚Äôs degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.\",\n",
    "    \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "    \"Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.\",\n",
    "    \"Deepak created multiple real-world projects ‚Äî from a Netflix clone to data analysis dashboards ‚Äî showcasing both creativity and logic.\",\n",
    "    \"He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.\",\n",
    "    \"Deepak‚Äôs story reflects passion, perseverance, and the belief that continuous learning can transform one‚Äôs life.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2939ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-47df70dff217e205cf4b860bbb11ff1556a1ab993f374b1de33cd037823e0abf\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-small\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f92564a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [generate_embeddings(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5601e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.05878288,  0.01717264, -0.0338271 , ...,  0.00438903,\n",
       "        -0.0014833 , -0.02586778], shape=(1536,)),\n",
       " array([ 0.00860733,  0.00794669, -0.03793576, ..., -0.0218264 ,\n",
       "         0.00357315, -0.02698444], shape=(1536,)),\n",
       " array([ 0.00157107, -0.00291296,  0.01863574, ..., -0.00658583,\n",
       "         0.01002349, -0.01296661], shape=(1536,)),\n",
       " array([ 0.01711475, -0.01486012,  0.04820827, ..., -0.01766816,\n",
       "         0.02066069,  0.0024327 ], shape=(1536,)),\n",
       " array([ 0.03916692, -0.0105021 ,  0.01395733, ..., -0.02891487,\n",
       "         0.02814199, -0.01163869], shape=(1536,)),\n",
       " array([-0.03450021,  0.01461001,  0.0322181 , ..., -0.02877255,\n",
       "        -0.0201475 , -0.02002444], shape=(1536,)),\n",
       " array([-0.01525764, -0.01136182,  0.02394184, ..., -0.03263809,\n",
       "        -0.03666659, -0.01676531], shape=(1536,)),\n",
       " array([ 0.02259899,  0.0227703 ,  0.02242768, ..., -0.02432639,\n",
       "         0.02302727, -0.02324141], shape=(1536,)),\n",
       " array([-0.01527787, -0.06384856,  0.00627351, ..., -0.02923696,\n",
       "        -0.03548248, -0.00058202], shape=(1536,)),\n",
       " array([ 0.04874954,  0.01769259, -0.00105991, ..., -0.00583742,\n",
       "         0.01240253, -0.00747316], shape=(1536,))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae8dce5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1344f211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e601802e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "482e0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(name=\"kumar_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da3e5016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'str'>\n",
      "1 <class 'str'>\n",
      "2 <class 'str'>\n",
      "3 <class 'str'>\n",
      "4 <class 'str'>\n",
      "5 <class 'str'>\n",
      "6 <class 'str'>\n",
      "7 <class 'str'>\n",
      "8 <class 'str'>\n",
      "9 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(texts)):\n",
    "    print(str(i),type(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1c2de3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'int'>\n",
      "1 <class 'int'>\n",
      "2 <class 'int'>\n",
      "3 <class 'int'>\n",
      "4 <class 'int'>\n",
      "5 <class 'int'>\n",
      "6 <class 'int'>\n",
      "7 <class 'int'>\n",
      "8 <class 'int'>\n",
      "9 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(texts)):\n",
    "    print(i,type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6977f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d96fee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.',\n",
       "  'From an early age, he was deeply curious about how machines work and how technology shapes the world.',\n",
       "  'Despite challenges, Deepak‚Äôs determination to learn and grow never faded.',\n",
       "  'He earned his Bachelor‚Äôs degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.',\n",
       "  'Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.',\n",
       "  'He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.',\n",
       "  'Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.',\n",
       "  'Deepak created multiple real-world projects ‚Äî from a Netflix clone to data analysis dashboards ‚Äî showcasing both creativity and logic.',\n",
       "  'He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.',\n",
       "  'Deepak‚Äôs story reflects passion, perseverance, and the belief that continuous learning can transform one‚Äôs life.'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None, None, None, None, None, None, None, None, None, None]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5062a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"hands-on experience with Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df26e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_query = generate_embeddings(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5c6e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00996748,  0.00263056,  0.00653042, ..., -0.03171746,\n",
       "       -0.00762787, -0.01103478], shape=(1536,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37db6cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['5', '4']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.',\n",
       "   'Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[0.7931717038154602, 1.0989384651184082]]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(query_embeddings=[embed_query], n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b5af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b59d9a93",
   "metadata": {},
   "source": [
    "# ‚òÅÔ∏è **ChromaDB Cloud Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc950056",
   "metadata": {},
   "source": [
    "## üìò **Overview**\n",
    "\n",
    "This guide explains how to:\n",
    "\n",
    "* Connect to **ChromaDB Cloud** using your API key and tenant ID.\n",
    "* Create a collection in your cloud database.\n",
    "* Upload texts and embeddings to store them online.\n",
    "* Manage your data in the cloud just like in the local version.\n",
    "\n",
    "The cloud version works the same way as local ChromaDB ‚Äî but all your data is saved on Chroma‚Äôs servers, not your computer.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è **Step 1: Install Required Packages**\n",
    "\n",
    "Before starting, make sure the `chromadb` library is installed:\n",
    "\n",
    "```bash\n",
    "pip install chromadb\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "This installs the official ChromaDB client library, which allows your Python code to communicate with both **local** and **cloud** databases.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© **Step 2: Import the Library**\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "You import the main ChromaDB module that lets you create clients, collections, and add/query data.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚òÅÔ∏è **Step 3: Connect to Chroma Cloud**\n",
    "\n",
    "```python\n",
    "client = chromadb.CloudClient(\n",
    "    api_key='ck-GnGngFgXZWvnZaT98NcpabLUGQzait46EACX4QUgYEUf',\n",
    "    tenant='1090dceb-688e-4571-8aab-b4d321488244',\n",
    "    database='test'\n",
    ")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "Here‚Äôs what each parameter means:\n",
    "\n",
    "| Parameter  | Description                                                                                         |\n",
    "| ---------- | --------------------------------------------------------------------------------------------------- |\n",
    "| `api_key`  | Your **personal secret key** that allows access to your cloud database. (Always keep this private!) |\n",
    "| `tenant`   | Your **tenant ID**, which identifies your organization or account in Chroma Cloud.                  |\n",
    "| `database` | The specific **database name** you want to work with inside your tenant.                            |\n",
    "\n",
    "üí° **In simple words:**\n",
    "You are logging in to your cloud-based Chroma account using credentials.\n",
    "Think of it like connecting to a remote SQL or Firebase database ‚Äî but this one stores embeddings and vectors.\n",
    "\n",
    "Once connected, `client` acts as your gateway to the cloud database.\n",
    "\n",
    "---\n",
    "\n",
    "## üß± **Step 4: Create a Collection**\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* A **collection** is like a *table* or *folder* inside your ChromaDB cloud database.\n",
    "* You can create multiple collections ‚Äî each one storing a different set of data (for example: user profiles, project notes, articles, etc.).\n",
    "* Here, you‚Äôre creating a new collection named `\"kumar_collection\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Step 5: Add Data (Texts and Embeddings)**\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "Let‚Äôs break this down:\n",
    "\n",
    "| Parameter    | Meaning                                                                                     |\n",
    "| ------------ | ------------------------------------------------------------------------------------------- |\n",
    "| `documents`  | The original text data (like sentences, paragraphs, or articles).                           |\n",
    "| `embeddings` | The numeric vectors (lists of numbers) representing the meaning of each text.               |\n",
    "| `ids`        | Unique identifiers (for example `\"0\"`, `\"1\"`, `\"2\"`, etc.) used to reference each document. |\n",
    "\n",
    "üí° You must make sure that:\n",
    "\n",
    "* The number of documents = number of embeddings = number of IDs.\n",
    "  Otherwise, Chroma will throw an error.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Example Data\n",
    "\n",
    "```python\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"He has hands-on experience with Python, Django, and Data Science tools.\"\n",
    "]\n",
    "\n",
    "embeddings = [\n",
    "    [0.12, 0.54, 0.33, 0.89],  # Example embedding for text 1\n",
    "    [0.77, 0.65, 0.49, 0.21]   # Example embedding for text 2\n",
    "]\n",
    "\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[\"1\", \"2\"]\n",
    ")\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "Here you added 2 texts, each with its embedding vector and a unique ID.\n",
    "In real usage, you‚Äôll generate embeddings using an API (like OpenAI or Euron) before adding them here.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç **Step 6: Verify That Data Was Uploaded**\n",
    "\n",
    "Once your data is uploaded, you can check it by calling:\n",
    "\n",
    "```python\n",
    "print(collection.count())  # Number of stored items\n",
    "print(collection.get())    # Retrieve stored documents and IDs\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* `count()` ‚Üí Tells you how many entries exist in the collection.\n",
    "* `get()` ‚Üí Returns the list of all stored texts, embeddings, and IDs.\n",
    "\n",
    "This helps confirm that your upload worked successfully.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Step 7: Query the Cloud Database (Optional)**\n",
    "\n",
    "If you want to search for similar sentences (like in the local setup), you can use:\n",
    "\n",
    "```python\n",
    "query = \"Python developer with strong analytical skills\"\n",
    "embed_query = generate_embeddings(query)  # Same API function as before\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[embed_query],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n",
    "‚úÖ **Explanation:**\n",
    "\n",
    "* `generate_embeddings(query)` converts your query text into a vector.\n",
    "* `collection.query()` searches through the cloud database for **most similar embeddings**.\n",
    "* `n_results=2` returns the top 2 closest matches.\n",
    "\n",
    "üí° This works the same way as local ChromaDB but uses the **remote (cloud) version**.\n",
    "\n",
    "---\n",
    "\n",
    "## üíæ **Step 8: Key Differences (Local vs Cloud)**\n",
    "\n",
    "| Feature      | Local ChromaDB                     | Cloud ChromaDB                              |\n",
    "| ------------ | ---------------------------------- | ------------------------------------------- |\n",
    "| Data Storage | Saved on your local machine        | Stored on Chroma‚Äôs cloud servers            |\n",
    "| Access       | Only accessible on your computer   | Can be accessed anywhere (with API key)     |\n",
    "| Persistence  | Controlled via `persist_directory` | Automatically handled by Chroma Cloud       |\n",
    "| Setup        | No API key needed                  | Requires API key, tenant, and database name |\n",
    "| Use Case     | Personal or small projects         | Team collaboration or production-scale apps |\n",
    "\n",
    "---\n",
    "\n",
    "## üß© **Step 9: Complete Cloud Example**\n",
    "\n",
    "Here‚Äôs the full working code for your cloud setup üëá\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "\n",
    "# 1Ô∏è‚É£ Connect to Chroma Cloud\n",
    "client = chromadb.CloudClient(\n",
    "    api_key='ck-GnGngFgXZWvnZaT98NcpabLUGQzait46EACX4QUgYEUf',\n",
    "    tenant='1090dceb-688e-4571-8aab-b4d321488244',\n",
    "    database='test'\n",
    ")\n",
    "\n",
    "# 2Ô∏è‚É£ Create or get a collection\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "\n",
    "# 3Ô∏è‚É£ Your text data\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, and Data Science tools.\"\n",
    "]\n",
    "\n",
    "# 4Ô∏è‚É£ Example embeddings (you can generate these using an API)\n",
    "embeddings = [\n",
    "    [0.12, 0.54, 0.33, 0.89],\n",
    "    [0.77, 0.65, 0.49, 0.21]\n",
    "]\n",
    "\n",
    "# 5Ô∏è‚É£ Add data to the collection\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")\n",
    "\n",
    "# 6Ô∏è‚É£ Check stored data\n",
    "print(\"Total documents:\", collection.count())\n",
    "print(\"Data stored in collection:\", collection.get())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîí **Step 10: Security Notes**\n",
    "\n",
    "* Never share your **API key** publicly (like on GitHub or in screenshots).\n",
    "* If it‚Äôs accidentally exposed, regenerate a new key from your Chroma Cloud dashboard.\n",
    "* Only use keys for trusted code or environments.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Summary Table**\n",
    "\n",
    "| Step | What It Does      | Example                                           |\n",
    "| ---- | ----------------- | ------------------------------------------------- |\n",
    "| 1    | Install ChromaDB  | `pip install chromadb`                            |\n",
    "| 2    | Import            | `import chromadb`                                 |\n",
    "| 3    | Connect to Cloud  | `chromadb.CloudClient(...)`                       |\n",
    "| 4    | Create Collection | `client.create_collection(\"kumar_collection\")`    |\n",
    "| 5    | Add Data          | `collection.add(documents, embeddings, ids)`      |\n",
    "| 6    | Check Data        | `collection.count()` / `collection.get()`         |\n",
    "| 7    | Query             | `collection.query(query_embeddings, n_results=2)` |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **In Short**\n",
    "\n",
    "You‚Äôve now learned how to:\n",
    "\n",
    "* Connect to **Chroma Cloud**\n",
    "* Create a **collection**\n",
    "* Add **documents + embeddings**\n",
    "* Perform **semantic search queries** ‚Äî all stored and managed securely in the cloud.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d23153a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.CloudClient(\n",
    "  api_key='ck-GnGngFgXZWvnZaT98NcpabLUGQzait46EACX4QUgYEUf',\n",
    "  tenant='1090dceb-688e-4571-8aab-b4d321488244',\n",
    "  database='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67523666",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(name=\"kumar_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9196274",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900581c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

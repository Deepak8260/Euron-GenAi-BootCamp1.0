{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376e8e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.1.1-cp39-abi3-win_amd64.whl (19.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from chromadb) (4.15.0)\n",
      "Collecting orjson>=3.9.12\n",
      "  Downloading orjson-3.11.3-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Collecting jsonschema>=4.19.0\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Collecting pybase64>=1.4.1\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting tenacity>=8.2.3\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Collecting overrides>=7.3.1\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (6.0.3)\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (1.75.1)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (2.11.10)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (2.2.6)\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting mmh3>=4.0.1\n",
      "  Downloading mmh3-5.2.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.23.1-cp310-cp310-win_amd64.whl (13.5 MB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting tomli>=1.1.0\n",
      "  Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting importlib-metadata>=4.6\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
      "Requirement already satisfied: idna in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.27.1-cp310-cp310-win_amd64.whl (228 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
      "Collecting durationpy>=0.7\n",
      "  Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Collecting urllib3<2.4.0,>=1.24.2\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.32.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting googleapis-common-protos~=1.57\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.37.0\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Collecting distro>=1.5.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.3)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.9.0)\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Collecting httptools>=0.6.3\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (PEP 517): started\n",
      "  Building wheel for pypika (PEP 517): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=db43cbf073dd07889ea6520348303c62880e266a913aa6ca279b362f881bd29a\n",
      "  Stored in directory: c:\\users\\kumar\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: zipp, importlib-metadata, urllib3, rpds-py, pyreadline3, pyasn1, opentelemetry-api, mdurl, attrs, rsa, referencing, pyasn1-modules, opentelemetry-semantic-conventions, opentelemetry-proto, oauthlib, markdown-it-py, humanfriendly, click, cachetools, websockets, websocket-client, watchfiles, uvicorn, tomli, shellingham, rich, requests-oauthlib, python-dotenv, pyproject-hooks, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-common, jsonschema-specifications, httptools, googleapis-common-protos, google-auth, flatbuffers, durationpy, distro, coloredlogs, backoff, typer, tenacity, pypika, pybase64, posthog, overrides, orjson, opentelemetry-exporter-otlp-proto-grpc, onnxruntime, mmh3, kubernetes, jsonschema, importlib-resources, build, bcrypt, chromadb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "Successfully installed attrs-25.4.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-6.2.0 chromadb-1.1.1 click-8.3.0 coloredlogs-15.0.1 distro-1.9.0 durationpy-0.10 flatbuffers-25.9.23 google-auth-2.41.1 googleapis-common-protos-1.70.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kubernetes-34.1.0 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 orjson-3.11.3 overrides-7.7.0 posthog-5.4.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pypika-0.48.9 pyproject-hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.1 referencing-0.36.2 requests-oauthlib-2.0.0 rich-14.2.0 rpds-py-0.27.1 rsa-4.9.1 shellingham-1.5.4 tenacity-9.1.2 tomli-2.3.0 typer-0.19.2 urllib3-2.3.0 uvicorn-0.37.0 watchfiles-1.1.0 websocket-client-1.9.0 websockets-15.0.1 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b830a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: chromadb\n",
      "Version: 1.1.1\n",
      "Summary: Chroma.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
      "License: \n",
      "Location: c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: tokenizers, opentelemetry-exporter-otlp-proto-grpc, typer, tqdm, onnxruntime, numpy, pydantic, uvicorn, build, pyyaml, overrides, bcrypt, jsonschema, opentelemetry-api, tenacity, typing-extensions, orjson, mmh3, httpx, posthog, grpcio, pybase64, opentelemetry-sdk, pypika, kubernetes, importlib-resources, rich\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17ca70",
   "metadata": {},
   "source": [
    "# 🧠 **Local ChromaDB Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8707096",
   "metadata": {},
   "source": [
    "This guide explains how to create a **local vector database using ChromaDB**, generate **embeddings from text using an external API**, and perform **semantic search** — all stored **locally on your computer**, not on the cloud.\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 **What You’ll Learn**\n",
    "\n",
    "By the end of this, you’ll know:\n",
    "\n",
    "1. What embeddings are and why they’re used.\n",
    "2. How to generate embeddings using an external API.\n",
    "3. How to store and search data locally using **ChromaDB**.\n",
    "4. How to run semantic queries to find similar text.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ **Step 1: Install Required Libraries**\n",
    "\n",
    "You need three Python packages:\n",
    "\n",
    "* `chromadb` → Local vector database\n",
    "* `requests` → To send API requests\n",
    "* `numpy` → To handle numerical vectors\n",
    "\n",
    "Install them using this command:\n",
    "\n",
    "```bash\n",
    "pip install chromadb requests numpy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 **Step 2: Import the Libraries**\n",
    "\n",
    "```python\n",
    "import requests      # For sending requests to the embedding API\n",
    "import numpy as np   # For numerical array operations\n",
    "import chromadb      # For creating and managing local vector database\n",
    "from chromadb.config import Settings  # For configuring local storage\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* `requests` helps us send text data to an API and receive embeddings (numbers).\n",
    "* `numpy` stores those numbers in a numerical format that’s easy to process.\n",
    "* `chromadb` is used to create, store, and search through these embeddings.\n",
    "* `Settings` lets us specify where ChromaDB should save the data on your system.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 **Step 3: Initialize a Local ChromaDB Client**\n",
    "\n",
    "```python\n",
    "client = chromadb.Client(\n",
    "    Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        persist_directory=\"./chroma_data\"\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* This line **starts a local ChromaDB database** on your computer.\n",
    "* `chroma_db_impl=\"duckdb+parquet\"` tells ChromaDB to use **DuckDB** (a lightweight local database) with **Parquet** file storage.\n",
    "* `persist_directory=\"./chroma_data\"` means all data will be saved in a folder called `chroma_data` on your machine.\n",
    "\n",
    "👉 So even if you close your program or restart your system, your stored data won’t be lost.\n",
    "\n",
    "---\n",
    "\n",
    "## 📄 **Step 4: Create Your Text Dataset**\n",
    "\n",
    "```python\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"From an early age, he was deeply curious about how machines work and how technology shapes the world.\",\n",
    "    \"Despite challenges, Deepak’s determination to learn and grow never faded.\",\n",
    "    \"He earned his Bachelor’s degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.\",\n",
    "    \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "    \"Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.\",\n",
    "    \"Deepak created multiple real-world projects — from a Netflix clone to data analysis dashboards — showcasing both creativity and logic.\",\n",
    "    \"He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.\",\n",
    "    \"Deepak’s story reflects passion, perseverance, and the belief that continuous learning can transform one’s life.\"\n",
    "]\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "This is your **dataset** — a list of sentences (called *documents* in ChromaDB).\n",
    "Each sentence will be converted into a **numerical embedding**, stored in the database, and later used for **similarity searches**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 **Step 5: Generate Embeddings Using an External API**\n",
    "\n",
    "```python\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"  # API endpoint\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-47df70dff217e205cf4b860bbb11ff1556a1ab993f374b1de33cd037823e0abf\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-small\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)  # Send POST request\n",
    "    data = response.json()  # Convert API response to Python dictionary\n",
    "    \n",
    "    embedding = np.array(data['data'][0]['embedding'])  # Extract the actual numbers\n",
    "    return embedding\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "1. We define a function `generate_embeddings(text)` that takes a sentence as input.\n",
    "2. The API (Euron’s Embedding API) converts your text into an **embedding vector** (a list of floating-point numbers).\n",
    "3. `requests.post()` sends the text to the API, and `response.json()` gets the reply.\n",
    "4. `embedding` stores the numeric vector returned by the API as a **NumPy array** for easy handling.\n",
    "\n",
    "👉 **Why embeddings?**\n",
    "Embeddings turn words into numbers that capture meaning.\n",
    "For example:\n",
    "\n",
    "* “Python developer” and “Software engineer” will have similar embeddings.\n",
    "* “Banana” and “Car” will have very different embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 **Step 6: Generate Embeddings for All Sentences**\n",
    "\n",
    "```python\n",
    "embeddings = [generate_embeddings(t) for t in texts]\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "This line **loops through every sentence** in the `texts` list and calls the `generate_embeddings()` function for each one.\n",
    "The result is a list of numerical vectors — one for each text.\n",
    "\n",
    "Now you have:\n",
    "\n",
    "* `texts` → the original text data\n",
    "* `embeddings` → the numerical version of each text\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 **Step 7: Create a Collection in ChromaDB**\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* A **collection** is like a folder or table inside ChromaDB.\n",
    "* You can store multiple documents and embeddings inside it.\n",
    "* Here, the collection is named `\"kumar_collection\"`.\n",
    "\n",
    "👉 You can later create other collections like `\"resume_data\"`, `\"project_notes\"`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 **Step 8: Add Your Data to the Collection**\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=texts,                        # Original text data\n",
    "    embeddings=embeddings,                  # Numeric embeddings\n",
    "    ids=[str(i) for i in range(len(texts))] # Unique IDs for each text\n",
    ")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "This stores everything inside ChromaDB.\n",
    "\n",
    "* `documents`: the actual sentences.\n",
    "* `embeddings`: the numerical representations.\n",
    "* `ids`: unique identifiers (`\"0\"`, `\"1\"`, `\"2\"`, …) for each text.\n",
    "\n",
    "Now ChromaDB knows which embedding belongs to which document.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **Step 9: Check What’s Stored**\n",
    "\n",
    "```python\n",
    "print(collection.count())   # Shows total number of stored items\n",
    "print(collection.get())     # Retrieves stored data (texts, embeddings, IDs)\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* `count()` tells you how many documents exist in your collection.\n",
    "* `get()` returns everything that’s stored — including your documents and IDs.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 **Step 10: Query Your Database (Semantic Search)**\n",
    "\n",
    "Now let’s find which stored sentences are **most similar** to a new input query.\n",
    "\n",
    "```python\n",
    "query = \"hands-on experience with Python\"\n",
    "embed_query = generate_embeddings(query)\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[embed_query],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "1. You create a new query text (`\"hands-on experience with Python\"`).\n",
    "2. Convert it into an embedding using the same API (`generate_embeddings(query)`).\n",
    "3. `collection.query()` searches inside your database for **the most similar stored embeddings**.\n",
    "4. `n_results=2` means you want the top 2 most similar sentences.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧾 **Sample Output**\n",
    "\n",
    "```python\n",
    "{\n",
    "  'ids': [['5', '4']],\n",
    "  'documents': [[\n",
    "      \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "      \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\"\n",
    "  ]],\n",
    "  'distances': [[0.7931717038154602, 1.0989384651184082]]\n",
    "}\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* `'ids'`: IDs of the most similar documents found.\n",
    "* `'documents'`: The actual text results.\n",
    "* `'distances'`: How close each result is to your query.\n",
    "\n",
    "  * Smaller distance = higher similarity.\n",
    "\n",
    "So the result shows that:\n",
    "\n",
    "> The query “hands-on experience with Python” is most similar to the sentence about Deepak’s hands-on Python experience (ID 5).\n",
    "\n",
    "---\n",
    "\n",
    "## 💾 **Step 11: Saving and Reloading Data**\n",
    "\n",
    "Your data is already saved locally (because we used `persist_directory=\"./chroma_data\"`).\n",
    "If you restart your Python program, you can reload the same collection like this:\n",
    "\n",
    "```python\n",
    "from chromadb.config import Settings\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client(\n",
    "    Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        persist_directory=\"./chroma_data\"\n",
    "    )\n",
    ")\n",
    "\n",
    "collection = client.get_collection(\"kumar_collection\")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* This reopens the database stored in `./chroma_data`.\n",
    "* You can now continue querying or adding new data without losing anything.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **Step 12: Full Working Code (Everything Together)**\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# 1️⃣ Initialize ChromaDB (local persistent mode)\n",
    "client = chromadb.Client(\n",
    "    Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=\"./chroma_data\")\n",
    ")\n",
    "\n",
    "# 2️⃣ Prepare the text dataset\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"From an early age, he was deeply curious about how machines work and how technology shapes the world.\",\n",
    "    \"Despite challenges, Deepak’s determination to learn and grow never faded.\",\n",
    "    \"He earned his Bachelor’s degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.\",\n",
    "    \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "    \"Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.\",\n",
    "    \"Deepak created multiple real-world projects — from a Netflix clone to data analysis dashboards — showcasing both creativity and logic.\",\n",
    "    \"He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.\",\n",
    "    \"Deepak’s story reflects passion, perseverance, and the belief that continuous learning can transform one’s life.\"\n",
    "]\n",
    "\n",
    "# 3️⃣ Function to generate embeddings\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-47df70dff217e205cf4b860bbb11ff1556a1ab993f374b1de33cd037823e0abf\"\n",
    "    }\n",
    "    payload = {\"input\": text, \"model\": \"text-embedding-3-small\"}\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    return embedding\n",
    "\n",
    "# 4️⃣ Generate embeddings for all texts\n",
    "embeddings = [generate_embeddings(t) for t in texts]\n",
    "\n",
    "# 5️⃣ Create a collection and add data\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "collection.add(documents=texts, embeddings=embeddings, ids=[str(i) for i in range(len(texts))])\n",
    "\n",
    "# 6️⃣ Query for similar text\n",
    "query = \"hands-on experience with Python\"\n",
    "embed_query = generate_embeddings(query)\n",
    "results = collection.query(query_embeddings=[embed_query], n_results=2)\n",
    "\n",
    "# 7️⃣ Show results\n",
    "print(results)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Final Summary**\n",
    "\n",
    "| Step | What It Does        | Explanation                                   |\n",
    "| ---- | ------------------- | --------------------------------------------- |\n",
    "| 1    | Initialize ChromaDB | Creates a local database folder to store data |\n",
    "| 2    | Prepare texts       | List of sentences you want to store           |\n",
    "| 3    | Generate embeddings | Converts text → numeric vectors               |\n",
    "| 4    | Add to collection   | Stores texts + embeddings in ChromaDB         |\n",
    "| 5    | Query               | Searches for the most similar texts           |\n",
    "| 6    | Reload              | Allows reuse of the same local database later |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9aaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"From an early age, he was deeply curious about how machines work and how technology shapes the world.\",\n",
    "    \"Despite challenges, Deepak’s determination to learn and grow never faded.\",\n",
    "    \"He earned his Bachelor’s degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.\",\n",
    "    \"Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.\",\n",
    "    \"Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.\",\n",
    "    \"Deepak created multiple real-world projects — from a Netflix clone to data analysis dashboards — showcasing both creativity and logic.\",\n",
    "    \"He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.\",\n",
    "    \"Deepak’s story reflects passion, perseverance, and the belief that continuous learning can transform one’s life.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2939ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-47df70dff217e205cf4b860bbb11ff1556a1ab993f374b1de33cd037823e0abf\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-small\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f92564a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [generate_embeddings(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5601e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.05878288,  0.01717264, -0.0338271 , ...,  0.00438903,\n",
       "        -0.0014833 , -0.02586778], shape=(1536,)),\n",
       " array([ 0.00860733,  0.00794669, -0.03793576, ..., -0.0218264 ,\n",
       "         0.00357315, -0.02698444], shape=(1536,)),\n",
       " array([ 0.00157107, -0.00291296,  0.01863574, ..., -0.00658583,\n",
       "         0.01002349, -0.01296661], shape=(1536,)),\n",
       " array([ 0.01711475, -0.01486012,  0.04820827, ..., -0.01766816,\n",
       "         0.02066069,  0.0024327 ], shape=(1536,)),\n",
       " array([ 0.03916692, -0.0105021 ,  0.01395733, ..., -0.02891487,\n",
       "         0.02814199, -0.01163869], shape=(1536,)),\n",
       " array([-0.03450021,  0.01461001,  0.0322181 , ..., -0.02877255,\n",
       "        -0.0201475 , -0.02002444], shape=(1536,)),\n",
       " array([-0.01525764, -0.01136182,  0.02394184, ..., -0.03263809,\n",
       "        -0.03666659, -0.01676531], shape=(1536,)),\n",
       " array([ 0.02259899,  0.0227703 ,  0.02242768, ..., -0.02432639,\n",
       "         0.02302727, -0.02324141], shape=(1536,)),\n",
       " array([-0.01527787, -0.06384856,  0.00627351, ..., -0.02923696,\n",
       "        -0.03548248, -0.00058202], shape=(1536,)),\n",
       " array([ 0.04874954,  0.01769259, -0.00105991, ..., -0.00583742,\n",
       "         0.01240253, -0.00747316], shape=(1536,))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae8dce5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1344f211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e601802e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "482e0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(name=\"kumar_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da3e5016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'str'>\n",
      "1 <class 'str'>\n",
      "2 <class 'str'>\n",
      "3 <class 'str'>\n",
      "4 <class 'str'>\n",
      "5 <class 'str'>\n",
      "6 <class 'str'>\n",
      "7 <class 'str'>\n",
      "8 <class 'str'>\n",
      "9 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(texts)):\n",
    "    print(str(i),type(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1c2de3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'int'>\n",
      "1 <class 'int'>\n",
      "2 <class 'int'>\n",
      "3 <class 'int'>\n",
      "4 <class 'int'>\n",
      "5 <class 'int'>\n",
      "6 <class 'int'>\n",
      "7 <class 'int'>\n",
      "8 <class 'int'>\n",
      "9 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(texts)):\n",
    "    print(i,type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6977f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d96fee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.',\n",
       "  'From an early age, he was deeply curious about how machines work and how technology shapes the world.',\n",
       "  'Despite challenges, Deepak’s determination to learn and grow never faded.',\n",
       "  'He earned his Bachelor’s degree in Computer Applications (BCA) from Bhadrak Autonomous College, Odisha.',\n",
       "  'Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.',\n",
       "  'He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.',\n",
       "  'Driven by curiosity, he constantly explores AI, machine learning, and data visualization to expand his expertise.',\n",
       "  'Deepak created multiple real-world projects — from a Netflix clone to data analysis dashboards — showcasing both creativity and logic.',\n",
       "  'He actively shares valuable Python insights and learning tips on LinkedIn to help others grow in their tech journey.',\n",
       "  'Deepak’s story reflects passion, perseverance, and the belief that continuous learning can transform one’s life.'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None, None, None, None, None, None, None, None, None, None]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5062a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"hands-on experience with Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df26e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_query = generate_embeddings(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5c6e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00996748,  0.00263056,  0.00653042, ..., -0.03171746,\n",
       "       -0.00762787, -0.01103478], shape=(1536,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37db6cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['5', '4']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['He has hands-on experience with Python, Django, Flask, HTML, CSS, JavaScript, and various Data Science tools.',\n",
       "   'Deepak is a passionate Python developer and aspiring Data Scientist with strong analytical and problem-solving skills.']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[0.7931717038154602, 1.0989384651184082]]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(query_embeddings=[embed_query], n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b5af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b59d9a93",
   "metadata": {},
   "source": [
    "# ☁️ **ChromaDB Cloud Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc950056",
   "metadata": {},
   "source": [
    "## 📘 **Overview**\n",
    "\n",
    "This guide explains how to:\n",
    "\n",
    "* Connect to **ChromaDB Cloud** using your API key and tenant ID.\n",
    "* Create a collection in your cloud database.\n",
    "* Upload texts and embeddings to store them online.\n",
    "* Manage your data in the cloud just like in the local version.\n",
    "\n",
    "The cloud version works the same way as local ChromaDB — but all your data is saved on Chroma’s servers, not your computer.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ **Step 1: Install Required Packages**\n",
    "\n",
    "Before starting, make sure the `chromadb` library is installed:\n",
    "\n",
    "```bash\n",
    "pip install chromadb\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "This installs the official ChromaDB client library, which allows your Python code to communicate with both **local** and **cloud** databases.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 **Step 2: Import the Library**\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "You import the main ChromaDB module that lets you create clients, collections, and add/query data.\n",
    "\n",
    "---\n",
    "\n",
    "## ☁️ **Step 3: Connect to Chroma Cloud**\n",
    "\n",
    "```python\n",
    "client = chromadb.CloudClient(\n",
    "    api_key='ck-GnGngFgXZWvnZaT98NcpabLUGQzait46EACX4QUgYEUf',\n",
    "    tenant='1090dceb-688e-4571-8aab-b4d321488244',\n",
    "    database='test'\n",
    ")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "Here’s what each parameter means:\n",
    "\n",
    "| Parameter  | Description                                                                                         |\n",
    "| ---------- | --------------------------------------------------------------------------------------------------- |\n",
    "| `api_key`  | Your **personal secret key** that allows access to your cloud database. (Always keep this private!) |\n",
    "| `tenant`   | Your **tenant ID**, which identifies your organization or account in Chroma Cloud.                  |\n",
    "| `database` | The specific **database name** you want to work with inside your tenant.                            |\n",
    "\n",
    "💡 **In simple words:**\n",
    "You are logging in to your cloud-based Chroma account using credentials.\n",
    "Think of it like connecting to a remote SQL or Firebase database — but this one stores embeddings and vectors.\n",
    "\n",
    "Once connected, `client` acts as your gateway to the cloud database.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 **Step 4: Create a Collection**\n",
    "\n",
    "```python\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* A **collection** is like a *table* or *folder* inside your ChromaDB cloud database.\n",
    "* You can create multiple collections — each one storing a different set of data (for example: user profiles, project notes, articles, etc.).\n",
    "* Here, you’re creating a new collection named `\"kumar_collection\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **Step 5: Add Data (Texts and Embeddings)**\n",
    "\n",
    "```python\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "Let’s break this down:\n",
    "\n",
    "| Parameter    | Meaning                                                                                     |\n",
    "| ------------ | ------------------------------------------------------------------------------------------- |\n",
    "| `documents`  | The original text data (like sentences, paragraphs, or articles).                           |\n",
    "| `embeddings` | The numeric vectors (lists of numbers) representing the meaning of each text.               |\n",
    "| `ids`        | Unique identifiers (for example `\"0\"`, `\"1\"`, `\"2\"`, etc.) used to reference each document. |\n",
    "\n",
    "💡 You must make sure that:\n",
    "\n",
    "* The number of documents = number of embeddings = number of IDs.\n",
    "  Otherwise, Chroma will throw an error.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Example Data\n",
    "\n",
    "```python\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"He has hands-on experience with Python, Django, and Data Science tools.\"\n",
    "]\n",
    "\n",
    "embeddings = [\n",
    "    [0.12, 0.54, 0.33, 0.89],  # Example embedding for text 1\n",
    "    [0.77, 0.65, 0.49, 0.21]   # Example embedding for text 2\n",
    "]\n",
    "\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[\"1\", \"2\"]\n",
    ")\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "Here you added 2 texts, each with its embedding vector and a unique ID.\n",
    "In real usage, you’ll generate embeddings using an API (like OpenAI or Euron) before adding them here.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 **Step 6: Verify That Data Was Uploaded**\n",
    "\n",
    "Once your data is uploaded, you can check it by calling:\n",
    "\n",
    "```python\n",
    "print(collection.count())  # Number of stored items\n",
    "print(collection.get())    # Retrieve stored documents and IDs\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* `count()` → Tells you how many entries exist in the collection.\n",
    "* `get()` → Returns the list of all stored texts, embeddings, and IDs.\n",
    "\n",
    "This helps confirm that your upload worked successfully.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **Step 7: Query the Cloud Database (Optional)**\n",
    "\n",
    "If you want to search for similar sentences (like in the local setup), you can use:\n",
    "\n",
    "```python\n",
    "query = \"Python developer with strong analytical skills\"\n",
    "embed_query = generate_embeddings(query)  # Same API function as before\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[embed_query],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n",
    "✅ **Explanation:**\n",
    "\n",
    "* `generate_embeddings(query)` converts your query text into a vector.\n",
    "* `collection.query()` searches through the cloud database for **most similar embeddings**.\n",
    "* `n_results=2` returns the top 2 closest matches.\n",
    "\n",
    "💡 This works the same way as local ChromaDB but uses the **remote (cloud) version**.\n",
    "\n",
    "---\n",
    "\n",
    "## 💾 **Step 8: Key Differences (Local vs Cloud)**\n",
    "\n",
    "| Feature      | Local ChromaDB                     | Cloud ChromaDB                              |\n",
    "| ------------ | ---------------------------------- | ------------------------------------------- |\n",
    "| Data Storage | Saved on your local machine        | Stored on Chroma’s cloud servers            |\n",
    "| Access       | Only accessible on your computer   | Can be accessed anywhere (with API key)     |\n",
    "| Persistence  | Controlled via `persist_directory` | Automatically handled by Chroma Cloud       |\n",
    "| Setup        | No API key needed                  | Requires API key, tenant, and database name |\n",
    "| Use Case     | Personal or small projects         | Team collaboration or production-scale apps |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 **Step 9: Complete Cloud Example**\n",
    "\n",
    "Here’s the full working code for your cloud setup 👇\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "\n",
    "# 1️⃣ Connect to Chroma Cloud\n",
    "client = chromadb.CloudClient(\n",
    "    api_key='ck-GnGngFgXZWvnZaT98NcpabLUGQzait46EACX4QUgYEUf',\n",
    "    tenant='1090dceb-688e-4571-8aab-b4d321488244',\n",
    "    database='test'\n",
    ")\n",
    "\n",
    "# 2️⃣ Create or get a collection\n",
    "collection = client.create_collection(name=\"kumar_collection\")\n",
    "\n",
    "# 3️⃣ Your text data\n",
    "texts = [\n",
    "    \"Deepak Kumar Mohanty was born in Balasore, Odisha, India, to a humble and supportive family.\",\n",
    "    \"He has hands-on experience with Python, Django, Flask, and Data Science tools.\"\n",
    "]\n",
    "\n",
    "# 4️⃣ Example embeddings (you can generate these using an API)\n",
    "embeddings = [\n",
    "    [0.12, 0.54, 0.33, 0.89],\n",
    "    [0.77, 0.65, 0.49, 0.21]\n",
    "]\n",
    "\n",
    "# 5️⃣ Add data to the collection\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")\n",
    "\n",
    "# 6️⃣ Check stored data\n",
    "print(\"Total documents:\", collection.count())\n",
    "print(\"Data stored in collection:\", collection.get())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔒 **Step 10: Security Notes**\n",
    "\n",
    "* Never share your **API key** publicly (like on GitHub or in screenshots).\n",
    "* If it’s accidentally exposed, regenerate a new key from your Chroma Cloud dashboard.\n",
    "* Only use keys for trusted code or environments.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Summary Table**\n",
    "\n",
    "| Step | What It Does      | Example                                           |\n",
    "| ---- | ----------------- | ------------------------------------------------- |\n",
    "| 1    | Install ChromaDB  | `pip install chromadb`                            |\n",
    "| 2    | Import            | `import chromadb`                                 |\n",
    "| 3    | Connect to Cloud  | `chromadb.CloudClient(...)`                       |\n",
    "| 4    | Create Collection | `client.create_collection(\"kumar_collection\")`    |\n",
    "| 5    | Add Data          | `collection.add(documents, embeddings, ids)`      |\n",
    "| 6    | Check Data        | `collection.count()` / `collection.get()`         |\n",
    "| 7    | Query             | `collection.query(query_embeddings, n_results=2)` |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **In Short**\n",
    "\n",
    "You’ve now learned how to:\n",
    "\n",
    "* Connect to **Chroma Cloud**\n",
    "* Create a **collection**\n",
    "* Add **documents + embeddings**\n",
    "* Perform **semantic search queries** — all stored and managed securely in the cloud.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d23153a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.CloudClient(\n",
    "  api_key='ck-GnGngFgXZWvnZaT98NcpabLUGQzait46EACX4QUgYEUf',\n",
    "  tenant='1090dceb-688e-4571-8aab-b4d321488244',\n",
    "  database='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67523666",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(name=\"kumar_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9196274",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=texts,\n",
    "    embeddings=embeddings,\n",
    "    ids=[str(i) for i in range(len(texts))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900581c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634c4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ed195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "Deepak Kumar Mohanty is from Balasore, Odisha, India. He completed his BCA at Bhadrak Autonomous College, Odisha, and is currently preparing for a Data Scientist role in the IT industry. Deepak is 21 years old, 172 cm tall, and weighs 91 kg. He is highly ambitious, committed to proving that it is possible to secure a Data Scientist job without a Master’s degree within 6 to 12 months. He describes himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves observing how machines work and is deeply fascinated by artificial intelligence and its impact on the IT industry.\n",
    "\n",
    "Deepak has strong technical skills in Python, Django, Flask, and other Python tools, along with knowledge of HTML, CSS, and JavaScript. He has worked on multiple projects including a Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app that performs basic math operations with responsive design. He also built a GitHub repository called 'Kumar Projects' where he uploads data science-related work, such as the 'Analysis and Visualization of Global Population Data in 2021'. His dataset work includes analyzing data with columns such as Country Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasing his growth in data science.\n",
    "\n",
    "He is highly interested in statistics and hypothesis testing, and he has completed day 6 of a 'Statistics for Data Science' course. He often requests clear, step-by-step explanations in simple words and prefers visual aids or diagrams to fully understand complex topics. He explores advanced Python concepts such as interning, object identity for mutable and immutable types, duck typing, private member access, and the use of super() in class hierarchies. He also practices embeddings, vector search, and cosine similarity for NLP, where he once faced a 'ModuleNotFoundError: No module named sentence_transformers' issue and learned to install the missing library. Deepak relates the concept of vector norms to the Pythagoras theorem for better understanding.\n",
    "\n",
    "Deepak is also active on LinkedIn, where he shares knowledge through carousels and posts about hidden Python concepts, tips, and memory optimization tricks. He once created a carousel explaining single-element tuples, another on Python interning, and one comparing object identity between immutable and mutable types. He prefers using dark, professional backgrounds for his carousel designs, with faded tones to highlight the content. His LinkedIn goals include growing his presence, creating a group focused on overlooked Python concepts, optimizing content with effective hashtags, and delivering value to the Python community.\n",
    "\n",
    "In addition to data science, Deepak works on voice assistant projects. One of his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with libraries like pyttsx3, speech_recognition, and win32com for text-to-speech, and explores building user interfaces using Tkinter. He is curious about combining speech recognition with text-to-speech seamlessly on Windows. He enjoys hands-on experimentation and is enthusiastic about building real-world AI-powered applications.\n",
    "\n",
    "Deepak follows Vishwa Mohan on YouTube for inspiration and learning. His personality blends technical curiosity with dedication and creativity. He enjoys exploring new concepts, sharing insights with others, and documenting his journey in tech. He values clarity and precision in communication and prefers avoiding pronouns in datasets to keep information unambiguous. Overall, Deepak is a motivated and passionate learner with strong technical skills, a growing project portfolio, and a clear vision to become a successful Data Scientist.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d6d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = data.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af87a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepak Kumar Mohanty is from Balasore, Odisha, India. He completed his BCA at Bhadrak Autonomous College, Odisha, and is currently preparing for a Data Scientist role in the IT industry. Deepak is 21 years old, 172 cm tall, and weighs 91 kg. He is highly ambitious, committed to proving that it is possible to secure a Data Scientist job without a Master’s degree within 6 to 12 months. He describes himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves observing how machines work and is deeply fascinated by artificial intelligence and its impact on the IT industry.\n",
      "\n",
      "Deepak has strong technical skills in Python, Django, Flask, and other Python tools, along with knowledge of HTML, CSS, and JavaScript. He has worked on multiple projects including a Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app that performs basic math operations with responsive design. He also built a GitHub repository called 'Kumar Projects' where he uploads data science-related work, such as the 'Analysis and Visualization of Global Population Data in 2021'. His dataset work includes analyzing data with columns such as Country Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasing his growth in data science.\n",
      "\n",
      "He is highly interested in statistics and hypothesis testing, and he has completed day 6 of a 'Statistics for Data Science' course. He often requests clear, step-by-step explanations in simple words and prefers visual aids or diagrams to fully understand complex topics. He explores advanced Python concepts such as interning, object identity for mutable and immutable types, duck typing, private member access, and the use of super() in class hierarchies. He also practices embeddings, vector search, and cosine similarity for NLP, where he once faced a 'ModuleNotFoundError: No module named sentence_transformers' issue and learned to install the missing library. Deepak relates the concept of vector norms to the Pythagoras theorem for better understanding.\n",
      "\n",
      "Deepak is also active on LinkedIn, where he shares knowledge through carousels and posts about hidden Python concepts, tips, and memory optimization tricks. He once created a carousel explaining single-element tuples, another on Python interning, and one comparing object identity between immutable and mutable types. He prefers using dark, professional backgrounds for his carousel designs, with faded tones to highlight the content. His LinkedIn goals include growing his presence, creating a group focused on overlooked Python concepts, optimizing content with effective hashtags, and delivering value to the Python community.\n",
      "\n",
      "In addition to data science, Deepak works on voice assistant projects. One of his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with libraries like pyttsx3, speech_recognition, and win32com for text-to-speech, and explores building user interfaces using Tkinter. He is curious about combining speech recognition with text-to-speech seamlessly on Windows. He enjoys hands-on experimentation and is enthusiastic about building real-world AI-powered applications.\n",
      "\n",
      "Deepak follows Vishwa Mohan on YouTube for inspiration and learning. His personality blends technical curiosity with dedication and creativity. He enjoys exploring new concepts, sharing insights with others, and documenting his journey in tech. He values clarity and precision in communication and prefers avoiding pronouns in datasets to keep information unambiguous. Overall, Deepak is a motivated and passionate learner with strong technical skills, a growing project portfolio, and a clear vision to become a successful Data Scientist.\n"
     ]
    }
   ],
   "source": [
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8595108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3768"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4bfdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_char = 500\n",
    "overlap = 100\n",
    "chunks = []\n",
    "i = 0\n",
    "while i< len(clean_data):\n",
    "    piece = clean_data[i:i+max_char]\n",
    "    chunks.append(piece)\n",
    "    i = i+ max_char - overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d98b3c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deepak Kumar Mohanty is from Balasore, Odisha, India. He completed his BCA at Bhadrak Autonomous College, Odisha, and is currently preparing for a Data Scientist role in the IT industry. Deepak is 21 years old, 172 cm tall, and weighs 91 kg. He is highly ambitious, committed to proving that it is possible to secure a Data Scientist job without a Master’s degree within 6 to 12 months. He describes himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves',\n",
       " 'himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves observing how machines work and is deeply fascinated by artificial intelligence and its impact on the IT industry.\\n\\nDeepak has strong technical skills in Python, Django, Flask, and other Python tools, along with knowledge of HTML, CSS, and JavaScript. He has worked on multiple projects including a Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app t',\n",
       " \"Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app that performs basic math operations with responsive design. He also built a GitHub repository called 'Kumar Projects' where he uploads data science-related work, such as the 'Analysis and Visualization of Global Population Data in 2021'. His dataset work includes analyzing data with columns such as Country Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasin\",\n",
       " \"ountry Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasing his growth in data science.\\n\\nHe is highly interested in statistics and hypothesis testing, and he has completed day 6 of a 'Statistics for Data Science' course. He often requests clear, step-by-step explanations in simple words and prefers visual aids or diagrams to fully understand complex topics. He explores advanced Python concepts such as interning, object identity for mutable and immutable \",\n",
       " \". He explores advanced Python concepts such as interning, object identity for mutable and immutable types, duck typing, private member access, and the use of super() in class hierarchies. He also practices embeddings, vector search, and cosine similarity for NLP, where he once faced a 'ModuleNotFoundError: No module named sentence_transformers' issue and learned to install the missing library. Deepak relates the concept of vector norms to the Pythagoras theorem for better understanding.\\n\\nDeepak \",\n",
       " 'pak relates the concept of vector norms to the Pythagoras theorem for better understanding.\\n\\nDeepak is also active on LinkedIn, where he shares knowledge through carousels and posts about hidden Python concepts, tips, and memory optimization tricks. He once created a carousel explaining single-element tuples, another on Python interning, and one comparing object identity between immutable and mutable types. He prefers using dark, professional backgrounds for his carousel designs, with faded tone',\n",
       " 'ble types. He prefers using dark, professional backgrounds for his carousel designs, with faded tones to highlight the content. His LinkedIn goals include growing his presence, creating a group focused on overlooked Python concepts, optimizing content with effective hashtags, and delivering value to the Python community.\\n\\nIn addition to data science, Deepak works on voice assistant projects. One of his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with ',\n",
       " 'f his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with libraries like pyttsx3, speech_recognition, and win32com for text-to-speech, and explores building user interfaces using Tkinter. He is curious about combining speech recognition with text-to-speech seamlessly on Windows. He enjoys hands-on experimentation and is enthusiastic about building real-world AI-powered applications.\\n\\nDeepak follows Vishwa Mohan on YouTube for inspiration and learning. Hi',\n",
       " 'ld AI-powered applications.\\n\\nDeepak follows Vishwa Mohan on YouTube for inspiration and learning. His personality blends technical curiosity with dedication and creativity. He enjoys exploring new concepts, sharing insights with others, and documenting his journey in tech. He values clarity and precision in communication and prefers avoiding pronouns in datasets to keep information unambiguous. Overall, Deepak is a motivated and passionate learner with strong technical skills, a growing project ',\n",
       " 'erall, Deepak is a motivated and passionate learner with strong technical skills, a growing project portfolio, and a clear vision to become a successful Data Scientist.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8acec060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae08d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "    headers = {\n",
    "        \n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-4aca7f0066db9e4df1204de08ff959f1dd8c0279d8750eff36de3a7bdb1e6101\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-small\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b471379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02237804  0.01795307 -0.00452745 ...  0.01837507  0.03518271\n",
      " -0.02058153]\n",
      "[-0.01347865 -0.0321925   0.00223342 ... -0.01958637  0.00830207\n",
      " -0.0176069 ]\n",
      "[-0.03493746 -0.004696   -0.02063557 ...  0.02096758  0.01015817\n",
      " -0.03258786]\n",
      "[-0.00212678 -0.00915796  0.06800397 ... -0.00545227  0.03020333\n",
      " -0.03673808]\n",
      "[-0.00049984  0.00327688  0.01935099 ... -0.00886498  0.01717274\n",
      " -0.02902649]\n",
      "[ 0.00783338 -0.02858108 -0.00320946 ...  0.00291059  0.02553669\n",
      " -0.01619502]\n",
      "[-0.00478342 -0.0259156   0.05941101 ... -0.00689318  0.00710032\n",
      " -0.02335319]\n",
      "[-0.01993684 -0.02076978  0.01989654 ...  0.01121111  0.01378383\n",
      " -0.00910189]\n",
      "[ 0.04160818 -0.02024986 -0.00312095 ...  0.01302452  0.023751\n",
      "  0.00761059]\n",
      "[ 0.0346763  -0.0179922   0.01305812 ...  0.01666115  0.02551955\n",
      " -0.00944935]\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    embedding = generate_embeddings(i)\n",
    "    print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e643ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp310-cp310-win_amd64.whl (18.2 MB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\kumar\\appdata\\roaming\\python\\python310\\site-packages (from faiss-cpu) (25.0)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bcb2713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43747257",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_list = []\n",
    "meta = []\n",
    "\n",
    "for idx , chunk in enumerate(chunks):\n",
    "    vec = generate_embeddings(chunk)\n",
    "    embed_list.append(vec.astype('float32'))\n",
    "    meta.append({\"id\":idx , \"text\":chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "529950e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.02237804,  0.01795307, -0.00452745, ...,  0.01837507,\n",
       "         0.03518271, -0.02058153], shape=(1536,), dtype=float32),\n",
       " array([-0.01348186, -0.0321741 ,  0.00224046, ..., -0.01961708,\n",
       "         0.00827799, -0.01762411], shape=(1536,), dtype=float32),\n",
       " array([-0.03488477, -0.00471493, -0.02062185, ...,  0.02100492,\n",
       "         0.0101577 , -0.03258635], shape=(1536,), dtype=float32),\n",
       " array([-0.00212678, -0.00915796,  0.06800397, ..., -0.00545227,\n",
       "         0.03020333, -0.03673808], shape=(1536,), dtype=float32),\n",
       " array([-0.00053027,  0.00326079,  0.01927347, ..., -0.00887694,\n",
       "         0.01718404, -0.02899886], shape=(1536,), dtype=float32),\n",
       " array([ 0.00783338, -0.02858108, -0.00320946, ...,  0.00291059,\n",
       "         0.02553669, -0.01619502], shape=(1536,), dtype=float32),\n",
       " array([-0.00478341, -0.0259156 ,  0.05941101, ..., -0.00689318,\n",
       "         0.00710032, -0.02335319], shape=(1536,), dtype=float32),\n",
       " array([-0.01993684, -0.02076978,  0.01989654, ...,  0.01121111,\n",
       "         0.01378383, -0.00910189], shape=(1536,), dtype=float32),\n",
       " array([ 0.04160818, -0.02024985, -0.00312095, ...,  0.01302452,\n",
       "         0.023751  ,  0.00761059], shape=(1536,), dtype=float32),\n",
       " array([ 0.0346989 , -0.01794612,  0.01301209, ...,  0.0166954 ,\n",
       "         0.0255193 , -0.00946073], shape=(1536,), dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc022a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'text': 'Deepak Kumar Mohanty is from Balasore, Odisha, India. He completed his BCA at Bhadrak Autonomous College, Odisha, and is currently preparing for a Data Scientist role in the IT industry. Deepak is 21 years old, 172 cm tall, and weighs 91 kg. He is highly ambitious, committed to proving that it is possible to secure a Data Scientist job without a Master’s degree within 6 to 12 months. He describes himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves'},\n",
       " {'id': 1,\n",
       "  'text': 'himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves observing how machines work and is deeply fascinated by artificial intelligence and its impact on the IT industry.\\n\\nDeepak has strong technical skills in Python, Django, Flask, and other Python tools, along with knowledge of HTML, CSS, and JavaScript. He has worked on multiple projects including a Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app t'},\n",
       " {'id': 2,\n",
       "  'text': \"Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app that performs basic math operations with responsive design. He also built a GitHub repository called 'Kumar Projects' where he uploads data science-related work, such as the 'Analysis and Visualization of Global Population Data in 2021'. His dataset work includes analyzing data with columns such as Country Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasin\"},\n",
       " {'id': 3,\n",
       "  'text': \"ountry Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasing his growth in data science.\\n\\nHe is highly interested in statistics and hypothesis testing, and he has completed day 6 of a 'Statistics for Data Science' course. He often requests clear, step-by-step explanations in simple words and prefers visual aids or diagrams to fully understand complex topics. He explores advanced Python concepts such as interning, object identity for mutable and immutable \"},\n",
       " {'id': 4,\n",
       "  'text': \". He explores advanced Python concepts such as interning, object identity for mutable and immutable types, duck typing, private member access, and the use of super() in class hierarchies. He also practices embeddings, vector search, and cosine similarity for NLP, where he once faced a 'ModuleNotFoundError: No module named sentence_transformers' issue and learned to install the missing library. Deepak relates the concept of vector norms to the Pythagoras theorem for better understanding.\\n\\nDeepak \"},\n",
       " {'id': 5,\n",
       "  'text': 'pak relates the concept of vector norms to the Pythagoras theorem for better understanding.\\n\\nDeepak is also active on LinkedIn, where he shares knowledge through carousels and posts about hidden Python concepts, tips, and memory optimization tricks. He once created a carousel explaining single-element tuples, another on Python interning, and one comparing object identity between immutable and mutable types. He prefers using dark, professional backgrounds for his carousel designs, with faded tone'},\n",
       " {'id': 6,\n",
       "  'text': 'ble types. He prefers using dark, professional backgrounds for his carousel designs, with faded tones to highlight the content. His LinkedIn goals include growing his presence, creating a group focused on overlooked Python concepts, optimizing content with effective hashtags, and delivering value to the Python community.\\n\\nIn addition to data science, Deepak works on voice assistant projects. One of his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with '},\n",
       " {'id': 7,\n",
       "  'text': 'f his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with libraries like pyttsx3, speech_recognition, and win32com for text-to-speech, and explores building user interfaces using Tkinter. He is curious about combining speech recognition with text-to-speech seamlessly on Windows. He enjoys hands-on experimentation and is enthusiastic about building real-world AI-powered applications.\\n\\nDeepak follows Vishwa Mohan on YouTube for inspiration and learning. Hi'},\n",
       " {'id': 8,\n",
       "  'text': 'ld AI-powered applications.\\n\\nDeepak follows Vishwa Mohan on YouTube for inspiration and learning. His personality blends technical curiosity with dedication and creativity. He enjoys exploring new concepts, sharing insights with others, and documenting his journey in tech. He values clarity and precision in communication and prefers avoiding pronouns in datasets to keep information unambiguous. Overall, Deepak is a motivated and passionate learner with strong technical skills, a growing project '},\n",
       " {'id': 9,\n",
       "  'text': 'erall, Deepak is a motivated and passionate learner with strong technical skills, a growing project portfolio, and a clear vision to become a successful Data Scientist.'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9436a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = np.vstack(embed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34b1c221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02237804,  0.01795307, -0.00452745, ...,  0.01837507,\n",
       "         0.03518271, -0.02058153],\n",
       "       [-0.01348186, -0.0321741 ,  0.00224046, ..., -0.01961708,\n",
       "         0.00827799, -0.01762411],\n",
       "       [-0.03488477, -0.00471493, -0.02062185, ...,  0.02100492,\n",
       "         0.0101577 , -0.03258635],\n",
       "       ...,\n",
       "       [-0.01993684, -0.02076978,  0.01989654, ...,  0.01121111,\n",
       "         0.01378383, -0.00910189],\n",
       "       [ 0.04160818, -0.02024985, -0.00312095, ...,  0.01302452,\n",
       "         0.023751  ,  0.00761059],\n",
       "       [ 0.0346989 , -0.01794612,  0.01301209, ...,  0.0166954 ,\n",
       "         0.0255193 , -0.00946073]], shape=(10, 1536), dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69212e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1536)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40221feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4fe31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f9964",
   "metadata": {},
   "source": [
    "# Why Do We Normalize Vectors Before Using FAISS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec9a4b",
   "metadata": {},
   "source": [
    "Imagine you have vectors that represent sentences or words — these are just lists of numbers that show the “meaning” in mathematical form.\n",
    "\n",
    "Before comparing how similar two vectors are (using Cosine Similarity), you need to make sure they are fairly compared — that’s where **L2 normalization** comes in.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Think of it like this:\n",
    "Suppose two people are saying the same sentence:\n",
    "- **Person A** says it loudly 🔊\n",
    "- **Person B** says it softly 🤫\n",
    "\n",
    "Both are saying the same thing, just with different volume.\n",
    "\n",
    "- In math terms:\n",
    "    - “Loudness” = **magnitude** (length) of the vector\n",
    "    - “Meaning” = **direction** of the vector\n",
    "- When we normalize, we make both voices the same loudness (set vector length = 1), so now we can focus only on meaning (the direction).\n",
    "\n",
    "---\n",
    "\n",
    "## 📏 What `faiss.normalize_L2(xb)` does:\n",
    "It goes through every vector in your dataset (each sentence embedding) and divides it by its own length, so that:\n",
    "\n",
    "$$\n",
    "\\text{new vector} = \\frac{\\text{original vector}}{|\\text{original vector}|}\n",
    "$$\n",
    "\n",
    "After this step:\n",
    "- Every vector’s length = 1\n",
    "- Only the angle/direction matters (i.e., meaning)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Why it’s important for FAISS:\n",
    "FAISS searches for similar vectors very fast.\n",
    "\n",
    "If you normalize the vectors first, then FAISS can simply use a **dot product** to find similar meanings — no need for long cosine calculations every time.\n",
    "\n",
    "So this single line:\n",
    "```python\n",
    "faiss.normalize_L2(xb)\n",
    "```\n",
    "means:\n",
    "> “Make all my sentence vectors the same length, so FAISS can compare their meanings directly and faster.”\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 Numerical Example (with 3D vectors)\n",
    "\n",
    "### Step 1: Imagine two sentence embeddings\n",
    "| Sentence              | Vector      |\n",
    "|-----------------------|-------------|\n",
    "| \"Python is amazing\"   | (2, 2, 1)   |\n",
    "| \"I love Python\"       | (4, 4, 2)   |\n",
    "\n",
    "These two sentences are similar in meaning, but the second one’s vector is just twice as large.\n",
    "\n",
    "### Step 2: Find their lengths (L2 norm)\n",
    "Formula:\n",
    "$$\n",
    "\\text{Length} = \\sqrt{x^2 + y^2 + z^2}\n",
    "$$\n",
    "- For (2,2,1):\n",
    "  $$\n",
    "  \\sqrt{2^2 + 2^2 + 1^2} = \\sqrt{9} = 3\n",
    "  $$\n",
    "- For (4,4,2):\n",
    "  $$\n",
    "  \\sqrt{4^2 + 4^2 + 2^2} = \\sqrt{36} = 6\n",
    "  $$\n",
    "\n",
    "### Step 3: Normalize them (make each vector’s length = 1)\n",
    "We divide each component by its length.\n",
    "- For (2,2,1):\n",
    "  $$\n",
    "  \\left(\\frac{2}{3}, \\frac{2}{3}, \\frac{1}{3}\\right) = (0.67, 0.67, 0.33)\n",
    "  $$\n",
    "- For (4,4,2):\n",
    "  $$\n",
    "  \\left(\\frac{4}{6}, \\frac{4}{6}, \\frac{2}{6}\\right) = (0.67, 0.67, 0.33)\n",
    "  $$\n",
    "\n",
    "✅ After normalization, both are exactly the same: **(0.67, 0.67, 0.33)**\n",
    "\n",
    "### Step 4: What this means\n",
    "- Before normalization:\n",
    "    - (4,4,2) looked bigger — like a louder voice 🎤\n",
    "    - (2,2,1) looked smaller — like a softer voice 🤫\n",
    "    - But both were pointing in the same direction (same meaning).\n",
    "- After normalization:\n",
    "    - They both now have equal length (1)\n",
    "    - FAISS can now compare only their direction, ignoring their size\n",
    "    - So FAISS will correctly understand that both mean the same thing (because their direction in vector space is identical).\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Why this matters\n",
    "- If you **don’t normalize**:\n",
    "    - FAISS may think (4,4,2) is more important just because it’s longer.\n",
    "- If you **do normalize**:\n",
    "    - FAISS focuses only on semantic similarity (the direction), not size.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Simple Analogy\n",
    "Think of vectors like arrows 🎯:\n",
    "- **Length** = how long the arrow is (volume or intensity)\n",
    "- **Direction** = where it points (meaning)\n",
    "\n",
    "L2 normalization simply shrinks or stretches all arrows so they’re the same length.\n",
    "Now, when you compare them, you only see which way they point, not how long they are.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎙️ Why FAISS gets confused without normalization\n",
    "FAISS (and any search algorithm) measures similarity using dot product by default.\n",
    "\n",
    "The dot product formula:\n",
    "$$\n",
    "\\mathbf{a}\\cdot\\mathbf{b} = |\\mathbf{a}| \\times |\\mathbf{b}| \\times \\cos(\\theta)\n",
    "$$\n",
    "It depends on three things:\n",
    "- Length of vector A\n",
    "- Length of vector B\n",
    "- Angle between them (θ = their direction difference)\n",
    "\n",
    "So if one vector is longer, the dot product automatically becomes larger, even if both mean the same thing.\n",
    "\n",
    "➡️ That’s why:\n",
    "- (4,4,2) gives a bigger score than (2,2,1) — just because it’s longer.\n",
    "- FAISS might mistakenly think it's more similar or more important, even though it’s not.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ What normalization fixes\n",
    "When we normalize, we divide each vector by its length, making its size = 1.\n",
    "\n",
    "| Vector      | Before         | After Normalization | Length |\n",
    "|-------------|----------------|--------------------|--------|\n",
    "| (2,2,1)     | (2,2,1)        | (0.67,0.67,0.33)   | 1      |\n",
    "| (4,4,2)     | (4,4,2)        | (0.67,0.67,0.33)   | 1      |\n",
    "\n",
    "✅ Both now have:\n",
    "- Equal size (1)\n",
    "- Same direction\n",
    "\n",
    "So FAISS now compares only the direction, because all lengths are the same.\n",
    "\n",
    "In the formula:\n",
    "$$\n",
    "\\mathbf{a}\\cdot\\mathbf{b} = 1\\times1\\times\\cos(\\theta) = \\cos(\\theta)\n",
    "$$\n",
    "Now the dot product ignores size completely — it tells us only about angle (meaning).\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Why this matters for “semantic” (meaning-based) search\n",
    "Semantic search wants to find what’s similar in meaning, not what’s longer.\n",
    "\n",
    "| Case                | What FAISS sees         | Result                        |\n",
    "|---------------------|------------------------|-------------------------------|\n",
    "| Without normalization | One vector is longer → looks “stronger” | Misleading result (not purely meaning-based) |\n",
    "| With normalization    | All vectors same length → only direction matters | Correct result (true semantic similarity) |\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Real-world analogy\n",
    "Imagine two books:\n",
    "- Book A: “Python is powerful.” (short book)\n",
    "- Book B: “Python is powerful.” (same text, but with large font)\n",
    "\n",
    "Both say the exact same thing, but the second book is physically bigger.\n",
    "- Without normalization → FAISS compares the font size and thinks Book B is “more important.”\n",
    "- With normalization → FAISS ignores the font size and focuses only on the words (meaning).\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 So when we say:\n",
    "> “FAISS compares only direction, ignoring size.”\n",
    "\n",
    "We mean:\n",
    "- Every vector is first scaled to have the same length (1).\n",
    "- Now, similarity depends only on how close their directions (angles) are in space.\n",
    "- The closer the direction, the more similar the meaning.\n",
    "- That’s why both (2,2,1) and (4,4,2) — after normalization — look identical to FAISS.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Your question (in simple words):\n",
    "> “If FAISS is just a simple vector database that stores 512-dimensional embeddings, then why will it get confused without normalization? Aren’t the embeddings themselves already carrying the meaning?”\n",
    "\n",
    "Perfect — that’s exactly the right thing to ask.\n",
    "\n",
    "### ⚙️ What FAISS actually does\n",
    "- FAISS does not understand meaning — it only performs mathematical vector search.\n",
    "- It doesn’t know what “cat”, “dog”, or “AI” means.\n",
    "- It only knows how to measure distance or similarity between numbers.\n",
    "\n",
    "So if you give FAISS two vectors like:\n",
    "- A = [4, 4, 2]\n",
    "- B = [2, 2, 1]\n",
    "\n",
    "it only sees them as points in space.\n",
    "\n",
    "### 📏 How FAISS compares vectors\n",
    "FAISS can use different similarity measures:\n",
    "- L2 distance → measures straight-line (Euclidean) distance\n",
    "- Dot product → measures angle and magnitude combined\n",
    "- Cosine similarity → measures angle only (direction)\n",
    "\n",
    "But FAISS doesn’t automatically know which you want.\n",
    "So you must prepare the data correctly depending on which comparison you want.\n",
    "\n",
    "### ⚖️ The role of normalization\n",
    "Suppose you are using dot product search (most common when using normalized embeddings).\n",
    "- Dot product depends on both:\n",
    "    - Direction (meaning)\n",
    "    - Magnitude (strength of the signal)\n",
    "- If we don’t normalize, the magnitude (size of numbers) will influence the similarity score.\n",
    "    - Vector [4,4,2] (large magnitude) gives a bigger dot product\n",
    "    - Vector [2,2,1] (smaller magnitude) gives a smaller dot product\n",
    "    - Even though they point in exactly the same direction (same meaning).\n",
    "- Hence FAISS may think:\n",
    "    > “Hmm, A looks more similar to the query than B”\n",
    "    even though both mean the same thing!\n",
    "- That’s what we mean by “FAISS gets confused.”\n",
    "\n",
    "### 🎯 What normalization fixes\n",
    "When we apply:\n",
    "```python\n",
    "faiss.normalize_L2(xb)\n",
    "```\n",
    "We scale every vector so its length = 1.\n",
    "Now the dot product between two vectors = cosine of the angle between them.\n",
    "That means:\n",
    "- If two vectors point in the same direction → cosine = 1 (perfect match)\n",
    "- If they point opposite → cosine = -1 (completely different)\n",
    "- So now FAISS can focus purely on direction = meaning, and ignore the magnitude = loudness or intensity.\n",
    "\n",
    "### 💡 Why this is essential for embeddings\n",
    "- Embeddings from models like sentence-transformers or OpenAI embeddings already encode meaning — but they don’t guarantee the vector magnitudes are equal.\n",
    "- So before using FAISS for semantic search, you normalize all embeddings once.\n",
    "- That tells FAISS:\n",
    "    > “Don’t worry about how long the vector is. Just compare how similar their meanings are.”\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 In short:\n",
    "| Concept                | Without Normalization      | With Normalization   |\n",
    "|------------------------|---------------------------|----------------------|\n",
    "| FAISS compares         | Magnitude + Direction     | Direction only       |\n",
    "| Meaning focus          | Lost or biased            | Preserved            |\n",
    "| Similarity measure     | Dot Product (biased)      | Cosine Similarity    |\n",
    "| Accuracy               | Lower                     | Higher               |\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ You Don’t Need FAISS to Normalize Vectors!\n",
    "\n",
    "Exactly, Deepak — you **don’t need FAISS** to normalize vectors. FAISS just provides a convenient function, but **normalization is pure math**. You can do it yourself using **NumPy** or any other library. ✅\n",
    "\n",
    "Let me explain fully.\n",
    "\n",
    "---\n",
    "\n",
    "### 1️⃣ The normalization formula\n",
    "For any vector $\\mathbf{v} = [v_1, v_2, ..., v_n]$:\n",
    "$$\n",
    "\\hat{\\mathbf{v}} = \\frac{\\mathbf{v}}{|\\mathbf{v}|}\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "|\\mathbf{v}| = \\sqrt{v_1^2 + v_2^2 + ... + v_n^2}\n",
    "$$\n",
    "- $|\\mathbf{v}|$ = magnitude (length) of the vector\n",
    "- $\\hat{\\mathbf{v}}$ = normalized vector (length = 1)\n",
    "\n",
    "So you’re **dividing each component of the vector by its magnitude**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ How to do it with NumPy (example)\n",
    "Suppose you have embeddings:\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Example 3D vectors\n",
    "vectors = np.array([[2, 2, 1],\n",
    "                    [4, 4, 2],\n",
    "                    [2, 3, 1]])\n",
    "\n",
    "# Compute L2 norm (magnitude) along axis=1 (rows)\n",
    "norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Divide each vector by its magnitude\n",
    "normalized_vectors = vectors / norms\n",
    "\n",
    "print(normalized_vectors)\n",
    "```\n",
    "**Output:**\n",
    "```\n",
    "[[0.667, 0.667, 0.333],\n",
    " [0.667, 0.667, 0.333],\n",
    " [0.534, 0.801, 0.267]]\n",
    "```\n",
    "✅ Exactly the same as `faiss.normalize_L2(vectors)` does internally.\n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ Important notes\n",
    "- FAISS just provides a **fast built-in function** (`faiss.normalize_L2`) that works efficiently for **large datasets**, but the **math is exactly the same**.\n",
    "- You can use **NumPy, PyTorch, or TensorFlow** — any library works.\n",
    "- After normalization, you can even use **FAISS IndexFlatIP** or **your own similarity calculation** — it will behave the same.\n",
    "\n",
    "---\n",
    "\n",
    "### 4️⃣ Summary\n",
    "| Method  | Formula                                                    | Works?                    |\n",
    "| ------- | ---------------------------------------------------------- | ------------------------- |\n",
    "| FAISS   | `faiss.normalize_L2(vectors)`                              | ✅ Yes, fast and optimized |\n",
    "| NumPy   | `vectors / np.linalg.norm(vectors, axis=1, keepdims=True)` | ✅ Yes, same result        |\n",
    "| PyTorch | `vectors / vectors.norm(p=2, dim=1, keepdim=True)`         | ✅ Yes, same result        |\n",
    "\n",
    "---\n",
    "\n",
    "💡 **Key insight:**\n",
    "Normalization is **just math** — FAISS only provides a convenient function for large embeddings.\n",
    "You can always do it manually.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "190bf428",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = xb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38c4ecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4a7b5",
   "metadata": {},
   "source": [
    "# Understanding How FAISS Index Works: Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "386e3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab23a27",
   "metadata": {},
   "source": [
    "No worries, let’s slow down and take this **step by step**, using a **simple analogy** so it clicks.\n",
    "\n",
    "We are talking about these two lines:\n",
    "\n",
    "```python\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(xb)\n",
    "```\n",
    "\n",
    "I’ll explain in the **simplest possible way**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Step 1: Creating the Index\n",
    "\n",
    "### `index = faiss.IndexFlatIP(dim)`\n",
    "\n",
    "Think of this like **creating an empty shelf in a library**.\n",
    "\n",
    "- **`IndexFlatIP`** = a type of shelf that stores books (vectors) and can compare them by “content similarity.”\n",
    "- **`dim`** = how big each book is (number of numbers in each vector, e.g., 512 dimensions).\n",
    "- Right now, the shelf is **empty**. Nothing is stored yet.\n",
    "\n",
    "**Analogy:**\n",
    "\n",
    "| Code                             | Analogy                                                                                              |\n",
    "| -------------------------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "| `index = faiss.IndexFlatIP(dim)` | “I’m creating an empty library shelf that can hold books of size `dim` and compare them by content.” |\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Step 2: Adding Vectors to the Index\n",
    "\n",
    "### `index.add(xb)`\n",
    "\n",
    "Now you have a bunch of books (vectors) — `xb` is your collection.\n",
    "\n",
    "- **`add(xb)`** = put all your books onto the shelf.\n",
    "- FAISS now **remembers every book** so it can compare them later.\n",
    "\n",
    "**Analogy:**\n",
    "\n",
    "| Code            | Analogy                                                                                                                        |\n",
    "| --------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| `index.add(xb)` | “I’m putting all my books on the shelf so that later, when someone asks for a book similar to a query, I can find it quickly.” |\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Step 3: Why Inner Product (IP) Matters\n",
    "\n",
    "- Inner product = dot product of two vectors.\n",
    "- If you already normalized vectors (length = 1), **dot product = cosine similarity**.\n",
    "- This means FAISS will now measure **how close the meanings are**, ignoring size.\n",
    "\n",
    "**Analogy:**\n",
    "- Each book has a theme (direction).\n",
    "- FAISS checks: “Which books have the **same theme** as the query?”\n",
    "- Because we normalized, it **doesn’t care about book thickness** (magnitude). Only theme (direction) matters.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Step 4: What Happens Internally\n",
    "\n",
    "After `index.add(xb)`:\n",
    "\n",
    "- FAISS stores all vectors in memory.\n",
    "- Each vector has an **ID**.\n",
    "- Later, when you give a query vector, FAISS will compare it to every stored vector using **dot product** and return the **most similar ones**.\n",
    "\n",
    "**Analogy:**\n",
    "- You hum a song → FAISS checks every song in your library → returns the **songs with the closest tune**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔑 Summary in Simplest Words\n",
    "\n",
    "1. `index = faiss.IndexFlatIP(dim)` → “Create an empty library shelf that can compare books by meaning.”\n",
    "2. `index.add(xb)` → “Put all my books (vectors) on the shelf so they are ready to be searched.”\n",
    "3. FAISS will use **dot product** (cosine similarity if normalized) to find the closest matches.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3e20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff3fb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = \"index_kumar.faiss\"\n",
    "meta_path = \"meta_kumar.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37842039",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index,index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a603483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11be5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta_path,'w') as f:\n",
    "    for item in meta:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a878087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4bd2e3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.65810657, 0.626843  , 0.56184447]], dtype=float32),\n",
       " array([[9, 8, 0]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is deepak\"\n",
    "q= generate_embeddings(query).astype('float32').reshape(1,-1)\n",
    "faiss.normalize_L2(q)\n",
    "index.search(q,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d1197",
   "metadata": {},
   "source": [
    "# Why .reshape(1, -1) is Used in FAISS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5875f",
   "metadata": {},
   "source": [
    "### Imagine a simple 1D array\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([10, 20, 30, 40, 50, 60])\n",
    "print(arr.shape)  # (6,)\n",
    "```\n",
    "\n",
    "Here, `arr` is a **1D vector** with 6 elements.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Reshape into 1 row\n",
    "\n",
    "```python\n",
    "new_arr = arr.reshape(1, -1)\n",
    "print(new_arr.shape)  # (1, 6)\n",
    "```\n",
    "\n",
    "* `1` → We want **1 row** (like 1 query).\n",
    "* `-1` → NumPy automatically calculates **6 columns** because all elements must fit.\n",
    "\n",
    "So `reshape(1, -1)` transforms a 1D vector into a **2D matrix with 1 row**.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Reshape into 2 rows\n",
    "\n",
    "```python\n",
    "new_arr2 = arr.reshape(2, -1)\n",
    "print(new_arr2.shape)  # (2, 3)\n",
    "```\n",
    "\n",
    "* `2` → We want **2 rows**.\n",
    "* `-1` → NumPy calculates columns automatically → 3 columns per row.\n",
    "\n",
    "**Result:**\n",
    "\n",
    "```\n",
    "[[10, 20, 30],\n",
    " [40, 50, 60]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Analogy\n",
    "\n",
    "Think of it as **arranging marbles in rows and columns**:\n",
    "\n",
    "* Original: a single line of 6 marbles.\n",
    "* `reshape(1, -1)`: 1 row, 6 marbles in that row.\n",
    "* `reshape(2, -1)`: 2 rows, NumPy figures out 3 marbles per row automatically.\n",
    "\n",
    "---\n",
    "\n",
    "In Faiss, `.reshape(1, -1)` is just like putting your **single query vector** into the right “shape” so the library can process it correctly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804072db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d19e6b5",
   "metadata": {},
   "source": [
    "# Testing whether after Normalization, the magnitude is approx 1 or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f83c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[4,5,6,7,8]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f22e4f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(13.784049)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd59251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "629b1ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.99999994)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916bd54",
   "metadata": {},
   "source": [
    "I am **testing and demonstrating the effect of L2 normalization** on a NumPy array, specifically by comparing the array's L2 norm **before** and **after** applying the Faiss L2 normalization function.\n",
    "\n",
    "The image shows a three-step process:\n",
    "\n",
    "***\n",
    "\n",
    "## 1. Initial State: Creating the Array and Measuring its Norm\n",
    "\n",
    "| Code | Purpose | Result |\n",
    "| :--- | :--- | :--- |\n",
    "| `test = np.array([[4,5,6,7,8]], dtype='float32')` | Creates a **2D NumPy array** containing a single vector (or row) of data. | `test` is the vector $[4, 5, 6, 7, 8]$. |\n",
    "| `np.linalg.norm(test)` | Calculates the **L2 norm** (Euclidean length) of the vector. | `13.784049` (This is $\\sqrt{4^2 + 5^2 + 6^2 + 7^2 + 8^2}$). |\n",
    "\n",
    "This step establishes the initial, un-normalized L2 norm of the vector, which is approximately $13.78$.\n",
    "\n",
    "***\n",
    "\n",
    "## 2. The Normalization Step\n",
    "\n",
    "| Code | Purpose |\n",
    "| :--- | :--- |\n",
    "| `faiss.normalize_l2(test)` | **Normalizes** the vector in-place. L2 normalization divides every element in the vector by the vector's L2 norm. |\n",
    "\n",
    "The Faiss function modifies the `test` array so that its new L2 norm will be $\\mathbf{1.0}$. Since this is an **in-place** operation, it changes the values stored within the original `test` variable.\n",
    "\n",
    "***\n",
    "\n",
    "## 3. Final State: Measuring the New Norm\n",
    "\n",
    "| Code | Purpose | Result |\n",
    "| :--- | :--- | :--- |\n",
    "| `np.linalg.norm(test)` | Recalculates the L2 norm of the **modified** `test` array. | `1.0000000` (or a number very close to 1.0 due to floating-point precision). |\n",
    "\n",
    "The final step **confirms that the `faiss.normalize_l2()` function worked correctly** by showing that the L2 norm of the vector has been successfully reduced (normalized) to **1.0**. This is the key characteristic of an L2-normalized vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e3c30",
   "metadata": {},
   "source": [
    "# Difference Between `np.linalg.norm` and `faiss.normalize_L2`: Step-by-Step Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e6c9f",
   "metadata": {},
   "source": [
    "## 1️⃣ What Does `np.linalg.norm` Do?\n",
    "\n",
    "- **Purpose:** Computes the **magnitude (length)** of a vector.\n",
    "- **Does it change the vector?** No, it just gives a number.\n",
    "- **Formula:** For a vector $v = [v_1, v_2, \\dots, v_n]$:\n",
    "\n",
    "$$\n",
    "|v|_2 = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2}\n",
    "$$\n",
    "\n",
    "- **Example:**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "test = np.array([3, 4])\n",
    "norm_val = np.linalg.norm(test)\n",
    "print(norm_val)  # 5.0\n",
    "```\n",
    "\n",
    "Explanation: $\\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5$ ✅\n",
    "\n",
    "Here, `np.linalg.norm` **does not change `test`**. It just tells you its length.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ What Does `faiss.normalize_L2` Do?\n",
    "\n",
    "- **Purpose:** **Normalizes the vector** so its length becomes **1**. This is called **L2 normalization**.\n",
    "- **Does it change the vector?** Yes, it **modifies the vector** in-place.\n",
    "- **Formula:**\n",
    "\n",
    "$$\n",
    "v_{\\text{normalized}} = \\frac{v}{|v|_2}\n",
    "$$\n",
    "\n",
    "- **Example:**\n",
    "\n",
    "```python\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "test = np.array([[3., 4.]])\n",
    "faiss.normalize_L2(test)\n",
    "print(test)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "[[0.6, 0.8]]\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Original vector length = 5 (as before)\n",
    "- Divide each element by 5 → `[3/5, 4/5] = [0.6, 0.8]`\n",
    "- New length = 1 ✅\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Key Differences Table\n",
    "\n",
    "| Feature             | `np.linalg.norm`                | `faiss.normalize_L2`                                                                                 |\n",
    "| ------------------- | ------------------------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "| What it does        | Computes the length of a vector | Scales the vector to have length 1                                                                   |\n",
    "| Output              | A **number**                    | A **modified vector**                                                                                |\n",
    "| Changes the vector? | ❌ No                            | ✅ Yes (in-place)                                                                                     |\n",
    "| Use case            | Just want magnitude             | Preprocessing vectors for similarity search (FAISS expects normalized vectors for cosine similarity) |\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Analogy\n",
    "\n",
    "- `np.linalg.norm`: “**Measure the rope** to see how long it is.”\n",
    "- `faiss.normalize_L2`: “**Stretch or shrink the rope** so it’s exactly 1 meter long.”\n",
    "\n",
    "---\n",
    "\n",
    "## Why Normalizing is Crucial in FAISS\n",
    "\n",
    "In Faiss, **normalizing is crucial** because when using **cosine similarity**, FAISS actually computes it as a **dot product**, and vectors must be normalized for this to correctly represent similarity.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Visual Example: Norm vs Normalize\n",
    "\n",
    "### Example: Using `np.linalg.norm`\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "test = np.array([3, 4])\n",
    "val = np.linalg.norm(test)\n",
    "print(val)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "5.0\n",
    "```\n",
    "\n",
    "Here’s what happens step by step:\n",
    "\n",
    "| Step | Description               | Result    |\n",
    "| ---- | ------------------------- | --------- |\n",
    "| 1    | Takes the vector `[3, 4]` | →         |\n",
    "| 2    | Squares each element      | `[9, 16]` |\n",
    "| 3    | Adds them up              | `25`      |\n",
    "| 4    | Takes square root         | `√25 = 5` |\n",
    "\n",
    "So the **magnitude (length)** of `[3, 4]` is `5`.\n",
    "That’s all it does — just gives you **how long** the vector is.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ It Doesn’t Normalize\n",
    "\n",
    "If you print `test` again:\n",
    "\n",
    "```python\n",
    "print(test)\n",
    "```\n",
    "\n",
    "You’ll still get:\n",
    "```\n",
    "[3 4]\n",
    "```\n",
    "So the vector itself is **unchanged**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ Summary Table: Norm vs Normalize\n",
    "\n",
    "| Function                   | What It Does                                                     | Changes Vector? | Output                            |\n",
    "| -------------------------- | ---------------------------------------------------------------- | --------------- | --------------------------------- |\n",
    "| `np.linalg.norm(test)`     | Calculates **magnitude only**                                    | ❌ No            | A **number** (e.g., `5.0`)        |\n",
    "| `faiss.normalize_L2(test)` | Divides each element by magnitude to make vector **unit length** | ✅ Yes           | A **vector** (e.g., `[0.6, 0.8]`) |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Analogy Recap\n",
    "\n",
    "- `np.linalg.norm` → “How long is this arrow?” 🧮\n",
    "- `faiss.normalize_L2` → “Make this arrow exactly **1 unit long**, pointing in the same direction.” 🎯\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Why Do We Use `np.linalg.norm()` At All?\n",
    "\n",
    "Because before you can **normalize** a vector (make its length = 1), you need to know **what its current length** is.\n",
    "That’s what `np.linalg.norm()` gives you — the **length (magnitude)** of the vector.\n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ How Normalization Works: Step-by-Step\n",
    "\n",
    "Suppose your vector is:\n",
    "\n",
    "```python\n",
    "v = np.array([3, 4])\n",
    "```\n",
    "\n",
    "Now you want to make it a **unit vector** (length = 1).\n",
    "How will you do that?\n",
    "You first need to know how long it is right now!\n",
    "\n",
    "### Step-by-step:\n",
    "\n",
    "1️⃣ **Find its magnitude:**\n",
    "```python\n",
    "length = np.linalg.norm(v)\n",
    "print(length)  # 5.0\n",
    "```\n",
    "\n",
    "2️⃣ **Divide each element by the length:**\n",
    "```python\n",
    "normalized = v / length\n",
    "print(normalized)  # [0.6, 0.8]\n",
    "```\n",
    "\n",
    "Now the new vector `[0.6, 0.8]` has a **length of 1**.\n",
    "✅ This process is called **L2 normalization**.\n",
    "\n",
    "---\n",
    "\n",
    "## 8️⃣ Why the Name `norm`?\n",
    "\n",
    "Because `norm` is the **mathematical name** for the *length* of a vector — and it’s used as the **basis for normalization**.\n",
    "\n",
    "> **Normalization = Divide by the norm.**\n",
    "\n",
    "That’s why:\n",
    "- `np.linalg.norm()` → calculates the **norm (length)**\n",
    "- `faiss.normalize_L2()` → uses the **norm internally** to make every vector have length 1\n",
    "\n",
    "---\n",
    "\n",
    "## 9️⃣ What Does FAISS Do Internally?\n",
    "\n",
    "When you call:\n",
    "```python\n",
    "faiss.normalize_L2(xb)\n",
    "```\n",
    "FAISS is doing this internally for each row vector:\n",
    "```python\n",
    "xb[i] = xb[i] / np.linalg.norm(xb[i])\n",
    "```\n",
    "So FAISS is using the *concept* of norm — it just automates it for you.\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣0️⃣ Final Summary Table\n",
    "\n",
    "| Function                | What It Does                    | Uses “norm”?           | Purpose                     |\n",
    "| ----------------------- | ------------------------------- | ---------------------- | --------------------------- |\n",
    "| `np.linalg.norm(x)`     | Finds the length of the vector  | ✅ Directly computes it | To measure magnitude        |\n",
    "| `faiss.normalize_L2(x)` | Divides vector by its norm (L2) | ✅ Uses norm internally | To make vectors unit length |\n",
    "\n",
    "---\n",
    "\n",
    "**In short:**\n",
    "We write or use `norm` because *it’s the foundation of normalization.*\n",
    "Without knowing the length, we can’t make the vector length = 1. 💪\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93efe2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8edd011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erall, Deepak is a motivated and passionate learner with strong technical skills, a growing project portfolio, and a clear vision to become a successful Data Scientist.\n",
      "Deepak Kumar Mohanty is from Balasore, Odisha, India. He completed his BCA at Bhadrak Autonomous College, Odisha, and is currently preparing for a Data Scientist role in the IT industry. Deepak is 21 years old, 172 cm tall, and weighs 91 kg. He is highly ambitious, committed to proving that it is possible to secure a Data Scientist job without a Master’s degree within 6 to 12 months. He describes himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves\n",
      "ld AI-powered applications.\n",
      "\n",
      "Deepak follows Vishwa Mohan on YouTube for inspiration and learning. His personality blends technical curiosity with dedication and creativity. He enjoys exploring new concepts, sharing insights with others, and documenting his journey in tech. He values clarity and precision in communication and prefers avoiding pronouns in datasets to keep information unambiguous. Overall, Deepak is a motivated and passionate learner with strong technical skills, a growing project \n"
     ]
    }
   ],
   "source": [
    "query = \"what is the qualification of deepak\"\n",
    "q= generate_embeddings(query).astype('float32').reshape(1,-1)\n",
    "faiss.normalize_L2(q)\n",
    "search = index.search(q,3)\n",
    "for i in search[1][0]:\n",
    "    print(chunks[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e52de3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.6580955 , 0.62682927, 0.5618104 ]], dtype=float32),\n",
       " array([[9, 8, 0]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bb8d00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 8]\n"
     ]
    }
   ],
   "source": [
    "print(search[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5b10fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erall, Deepak is a motivated and passionate learner with strong technical skills, a growing project portfolio, and a clear vision to become a successful Data Scientist.\n",
      "ld AI-powered applications.\n",
      "\n",
      "Deepak follows Vishwa Mohan on YouTube for inspiration and learning. His personality blends technical curiosity with dedication and creativity. He enjoys exploring new concepts, sharing insights with others, and documenting his journey in tech. He values clarity and precision in communication and prefers avoiding pronouns in datasets to keep information unambiguous. Overall, Deepak is a motivated and passionate learner with strong technical skills, a growing project \n",
      "Deepak Kumar Mohanty is from Balasore, Odisha, India. He completed his BCA at Bhadrak Autonomous College, Odisha, and is currently preparing for a Data Scientist role in the IT industry. Deepak is 21 years old, 172 cm tall, and weighs 91 kg. He is highly ambitious, committed to proving that it is possible to secure a Data Scientist job without a Master’s degree within 6 to 12 months. He describes himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves\n"
     ]
    }
   ],
   "source": [
    "for i in search[1][0]:\n",
    "    print(chunks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcc9617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deepak Kumar Mohanty is from Balasore, Odisha, India. He completed his BCA at Bhadrak Autonomous College, Odisha, and is currently preparing for a Data Scientist role in the IT industry. Deepak is 21 years old, 172 cm tall, and weighs 91 kg. He is highly ambitious, committed to proving that it is possible to secure a Data Scientist job without a Master’s degree within 6 to 12 months. He describes himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves',\n",
       " 'himself as a fast learner, a good listener, and very flexible in adopting new technologies. He loves observing how machines work and is deeply fascinated by artificial intelligence and its impact on the IT industry.\\n\\nDeepak has strong technical skills in Python, Django, Flask, and other Python tools, along with knowledge of HTML, CSS, and JavaScript. He has worked on multiple projects including a Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app t',\n",
       " \"Netflix homepage clone using HTML and CSS, an e-commerce website clone, and a React calculator app that performs basic math operations with responsive design. He also built a GitHub repository called 'Kumar Projects' where he uploads data science-related work, such as the 'Analysis and Visualization of Global Population Data in 2021'. His dataset work includes analyzing data with columns such as Country Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasin\",\n",
       " \"ountry Name and Population. Deepak’s GitHub projects are organized from basic to advanced, showcasing his growth in data science.\\n\\nHe is highly interested in statistics and hypothesis testing, and he has completed day 6 of a 'Statistics for Data Science' course. He often requests clear, step-by-step explanations in simple words and prefers visual aids or diagrams to fully understand complex topics. He explores advanced Python concepts such as interning, object identity for mutable and immutable \",\n",
       " \". He explores advanced Python concepts such as interning, object identity for mutable and immutable types, duck typing, private member access, and the use of super() in class hierarchies. He also practices embeddings, vector search, and cosine similarity for NLP, where he once faced a 'ModuleNotFoundError: No module named sentence_transformers' issue and learned to install the missing library. Deepak relates the concept of vector norms to the Pythagoras theorem for better understanding.\\n\\nDeepak \",\n",
       " 'pak relates the concept of vector norms to the Pythagoras theorem for better understanding.\\n\\nDeepak is also active on LinkedIn, where he shares knowledge through carousels and posts about hidden Python concepts, tips, and memory optimization tricks. He once created a carousel explaining single-element tuples, another on Python interning, and one comparing object identity between immutable and mutable types. He prefers using dark, professional backgrounds for his carousel designs, with faded tone',\n",
       " 'ble types. He prefers using dark, professional backgrounds for his carousel designs, with faded tones to highlight the content. His LinkedIn goals include growing his presence, creating a group focused on overlooked Python concepts, optimizing content with effective hashtags, and delivering value to the Python community.\\n\\nIn addition to data science, Deepak works on voice assistant projects. One of his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with ',\n",
       " 'f his key projects is JARVIS, a desktop voice assistant integrated with OpenAI. He experiments with libraries like pyttsx3, speech_recognition, and win32com for text-to-speech, and explores building user interfaces using Tkinter. He is curious about combining speech recognition with text-to-speech seamlessly on Windows. He enjoys hands-on experimentation and is enthusiastic about building real-world AI-powered applications.\\n\\nDeepak follows Vishwa Mohan on YouTube for inspiration and learning. Hi',\n",
       " 'ld AI-powered applications.\\n\\nDeepak follows Vishwa Mohan on YouTube for inspiration and learning. His personality blends technical curiosity with dedication and creativity. He enjoys exploring new concepts, sharing insights with others, and documenting his journey in tech. He values clarity and precision in communication and prefers avoiding pronouns in datasets to keep information unambiguous. Overall, Deepak is a motivated and passionate learner with strong technical skills, a growing project ',\n",
       " 'erall, Deepak is a motivated and passionate learner with strong technical skills, a growing project portfolio, and a clear vision to become a successful Data Scientist.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3fc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
